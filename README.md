# Awesome Deep learning and deep reinforcement learning papers

A list of recent papers regarding deep learning and deep reinforcement learning. They are sorted by time to see the recent papers first.
I will renew the recent papers and add notes to these papers.

The papers of after 2016 year are not in this file, and you can click the link to touch them.

## Table of Contents
- [Papers](#papers)
    - [2017 year](md/2017/deeplearning/dl.md)
      - [deep learning](md/2017/deeplearning/dl.md)
         - [deep learning](md/2017/deeplearning/dl.md#deep-learning) 
         - [adversarial network](md/2017/deeplearning/dl.md#adversarial-network)
         - [transfer learning](md/2017/deeplearning/dl.md#transfer-learning)
    - [2016 year](md/2016/deeplearning/dl.md)
        - [deep learning](md/2016/deeplearning/dl.md)
            - [deep learning](md/2016/deeplearning/dl.md#deep-learning)
            - [attention and memory](md/2016/deeplearning/dl.md#attention-and-memory)
            - [adversarial network](md/2016/deeplearning/dl.md#adversarial-network)
            - [transfer learning](md/2016/deeplearning/dl.md#transfer-learning)
        - [natural language process](md/2016/deeplearning/nlp.md)
            - [adversarial network](md/2016/deeplearning/nlp.md#adversarial-network)
            - [attention and memory](md/2016/deeplearning/nlp.md#attention-and-memory)
        - [deep reinforcement learning](md/2016/reinforcelearning/rl.md)
    - [2015 year](#2015)
        - [deep learning](#deep-learning)
        - [natural language process](#natural-language-process)
        - [adversarial network](#adversarial-network)
        - [attention and memory](#attention-and-memory)
        - [deep reinforcement learning](#deep-reinforcement-learning)
    - [2014 year](#2014)
        - [deep learning](#deep-learning-1)
        - [attention and memory](#attention-and-memory-1)
        - [deep reinforcement Learning](#deep-reinforcement-learning-1) 
    - [2013 year](#2013)
        - [deep learning](#deep-learning-2)
        - [deep reinforcement Learning](#deep-reinforcement-learning-2) 
    - [2012 year](md/2012.md)
    - [2011 year](md/2011.md)
    - [2010 year](md/2010.md)
    - [before 2010 year](md/before-2010.md)
- [Courses](#courses)
- [Books](#books)
- [Videos](#videos)
- [Software](#software)

# Papers

## 2015

### Deep learning

- A Diversity-Promoting Objective Function for Neural Conversation Models. [[pdf](docs/2015/A Diversity-Promoting Objective Function for Neural Conversation Models.pdf)] [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjghNPo-tLQAhULWLwKHZ6bB5sQFggsMAE&url=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FN16-1014&usg=AFQjCNE-WkcrMlvb2VudgN1271pPAV-ALg)]
- A Neural Algorithm of Artistic Style. [[arxiv](https://arxiv.org/abs/1508.06576)] [[code](https://github.com/titu1994/Neural-Style-Transfer)]
- A Neural Conversational Model. [[pdf]](docs/2015/A Neural Conversational Model.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjsnJOo-9LQAhXITLwKHb6IDjYQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.05869&usg=AFQjCNG8O97sWinlNfkyfEgPysuic8pXBA)]
- A Neural Network Approach to Context-Sensitive Generation of Conversational Responses. [[pdf]](docs/2015/A Neural Network Approach to Context-Sensitive Generation of Conversational Responses.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwi6sfPF-9LQAhVKVbwKHaKjDM8QFggsMAE&url=http%3A%2F%2Fwww-etud.iro.umontreal.ca%2F~sordonia%2Fpdf%2Fnaacl15.pdf&usg=AFQjCNFXJpaki2cwwGyTDAFnKKAFWsIoMA)]
- A Roadmap towards Machine Intelligence. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwivxdj8-9LQAhWBWbwKHaw1AgMQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.08130&usg=AFQjCNGL1YXbBqtEbePteiKtLdRpJMGsbw)]
- A Survey- Time Travel in Deep Learning Space- An Introduction to Deep Learning Models and How Deep Learning Models Evolved from the Initial Ideas. [[pdf]](docs/2015/A Survey- Time Travel in Deep Learning Space- An Introduction to Deep Learning Models and How Deep Learning Models Evolved from the Initial Ideas.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiTsdSu_NLQAhUKwbwKHYbBDRkQFggdMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1510.04781&usg=AFQjCNE77qGAxyoLWSDJepQsdH-dhmdLsQ)]
- [ADAM] <b>Adam: A Method for Stochastic Optimization</b>. [[pdf]](docs/2015/ADAM- A METHOD FOR STOCHASTIC OPTIMIZATION(2015).pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjNj9nq_NLQAhWBTrwKHRAYCNsQFggtMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1412.6980&usg=AFQjCNGoWw08vLoxCHTHcXPc4Y-jyOciXw)]
- <b>An Empirical Exploration of Recurrent Network Architectures.</b> [[pdf]](docs/2015/An Empirical Exploration of Recurrent Network Architectures(2015).pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjb_4HB_dLQAhXLXrwKHZohAl8QFgggMAA&url=http%3A%2F%2Fjmlr.org%2Fproceedings%2Fpapers%2Fv37%2Fjozefowicz15.pdf&usg=AFQjCNF0S7PLOOFJAsnaVD4GHptHN6D6JA)]
- [Batch Normalization- Accelerating Deep Network Training by Reducing Internal Covariate Shift.](http://blog.csdn.net/happynear/article/details/44238541)  [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiarozZ_tLQAhWKbbwKHQDxDbcQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1502.03167&usg=AFQjCNExSJ7DRNsgQhnYzEcH7g0i3nzu4Q)]
- Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj73Kqm_9LQAhUEv7wKHYAkDcoQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1507.04808&usg=AFQjCNG63pfd4i9Wz_nj6FEyOYWslBdl-g)]
- Correlational Neural Networks. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjo5rn6_9LQAhUKebwKHe-LBuEQFggdMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1504.07225&usg=AFQjCNHzdHZ0b2ZoxS5bpmxh5rsghbSw2Q)]
- Deconstructing the Ladder Network Architecture. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiOjJadgNPQAhWJWrwKHdsoBs8QFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.06430&usg=AFQjCNG7yS2esOcnwWBLTCekAMofapfSOg)]
- Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding. [[arxiv](https://arxiv.org/abs/1510.00149)]
- Deep Knowledge Tracing. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjh4Nu3gNPQAhUHbbwKHZM6DAkQFggiMAA&url=https%3A%2F%2Fweb.stanford.edu%2F~cpiech%2Fbio%2Fpapers%2FdeepKnowledgeTracing.pdf&usg=AFQjCNGMGxC1N0jAosfrPXtAp-4Y0ctTXw)]
- [ResNet] [Deep Residual Learning for Image Recognition](http://blog.csdn.net/cv_family_z/article/details/50328175). [[pdf]](docs/2015/Deep Residual Learning for Image Recognition.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjL2pzjgNPQAhVBxLwKHfHgBKgQFgguMAE&url=http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016%2Fpapers%2FHe_Deep_Residual_Learning_CVPR_2016_paper.pdf&usg=AFQjCNFGFwwaDLEa7-LDpSTqyUv107yaEg)]
- [ResNet] <b>Delving Deep into Rectifiers- Surpassing Human-Level Performance on ImageNet Classification</b>. [[pdf]](docs/2015/Delving Deep into Rectifiers- Surpassing Human-Level Performance on ImageNet Classification(2015).pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiyssepgdPQAhXLwLwKHSttBuoQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1502.01852&usg=AFQjCNECb3XvSFc_BHFAjE-j1BIst-BMXw)]
- <b>Distilling the Knowledge in a Neural Network</b>. [[pdf]](docs/2015/Distilling the Knowledge in a Neural Network.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjutISLgtPQAhVKbbwKHet8DK4QFgguMAE&url=https%3A%2F%2Fwww.cs.toronto.edu%2F~hinton%2Fabsps%2Fdistillation.pdf&usg=AFQjCNGI14ldA9QhBoMO-4vT-qfrBQrsZA)]
- Dropout as a Bayesian Approximation- Representing Model Uncertainty in Deep Learning. [[url](https://arxiv.org/pdf/1506.02142)]
- Effective LSTMs for Target-Dependent Sentiment Classification. [[arxiv](https://arxiv.org/abs/1512.01100)]
- <b>Hierarchical Recurrent Neural Network for Skeleton Based Action Recognition.</b> [[url](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Du_Hierarchical_Recurrent_Neural_2015_CVPR_paper.pdf)]
- Inside-Outside Net- Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks. [[pdf]](docs/2015/Inside-Outside Net- Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj99o-ThNPQAhUMe7wKHaJZAs0QFggvMAE&url=http%3A%2F%2Fimage-net.org%2Fchallenges%2Ftalks%2Fion-coco-talk-bell2015.pdf&usg=AFQjCNFUVYf-MUBT2BKQPsrBLTDlzFt5PA)]
- Learning Simple Algorithms from Examples. [[pdf]](docs/2015/Learning Simple Algorithms from Examples.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj_7vPWhNPQAhUJgLwKHWC1A7gQFggvMAE&url=http%3A%2F%2Fjmlr.org%2Fproceedings%2Fpapers%2Fv48%2Fzaremba16.pdf&usg=AFQjCNEQlbOwzlKS6eUdVuXIGrRtDfDVaA)]
- Learning to Transduce with Unbounded Memory. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjYu-D0hNPQAhUMNrwKHew8AsYQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.02516&usg=AFQjCNEeCL4SV0s8JCtxAARLeLz7S1kC0A)]
- Listen, Attend and Spell. [[pdf]](docs/2015/Listen, Attend and Spell.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjW4bqThdPQAhULf7wKHWS4Cl0QFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1508.01211&usg=AFQjCNEmyppRaNABjzOP4soC2IQd8M8hNw)]
- <b>LSTM A Search Space Odyssey</b>. [[pdf]](docs/2015/LSTM A Search Space Odyssey(2015).pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiigPSrhdPQAhWJW7wKHSH7D8IQFggrMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1503.04069&usg=AFQjCNEpZAcQ8c5a6GMsBWBAy-pbcbjS2g)]
- LSTM-based Deep Learning Models for non-factoid answer selection. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj-rpDLhdPQAhXJErwKHaPAAyoQFggtMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.04108&usg=AFQjCNEKrHqjvUSmXuI9zBwPBcMDDUOe5w)]
- Net2Net-Accelerating Learning via Knowledge Transfer. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiburbphtPQAhVCVbwKHVOuAcsQFgggMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.05641&usg=AFQjCNHYQzsRziUVIU8SAhq2H_XuLuiLcw)]
- Neural GPUs Learn Algorithms. [[pdf]](docs/2015/Neural GPUs Learn Algorithms.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjKoce8ndPQAhVFx7wKHdIZCtYQFggdMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.08228&usg=AFQjCNFSo5DutEjXcPPeHJOS2ZLhVSLKog)]
- Neural Programmer- Inducing Latent Programs with Gradient Descent. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjQg9nUndPQAhVDwLwKHbmaCskQFggsMAE&url=https%3A%2F%2Fpeople.cs.umass.edu%2F~arvind%2Fnp.pdf&usg=AFQjCNEpIyC6zWXQT44MmmZStNjMUSbHcw)]
- <b>Pointer Networks</b>. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjO2afkntPQAhXGw7wKHdjSAJIQFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.03134&usg=AFQjCNHyhe83B6QkuFCeActJjUHaiMB4Pg)]
- Poker-CNN- A Pattern Learning Strategy for Making Draws and Bets in Poker Games. [[pdf]](docs/2015/Poker-CNN- A Pattern Learning Strategy for Making Draws and Bets in Poker Games.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjZrJeXn9PQAhUByrwKHV2pBQEQFggrMAE&url=http%3A%2F%2Fcolinraffel.com%2Fpublications%2Faaai2016poker.pdf&usg=AFQjCNGpLMFh8m91SLrHvu7vBbCGy3CW_g)]
- Policy distillation. [[arxiv](https://arxiv.org/abs/1511.06295)]
- Regularizing RNNs by Stabilizing Activations. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjX9YWBoNPQAhUSNrwKHfg8AuwQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.08400&usg=AFQjCNGxE7PHSagmWUBIAw4zRLZx5fDxZQ)]
- ReNet- A Recurrent Neural Network Based Alternative to Convolutional Networks. [[pdf]](docs/2015/ReNet- A Recurrent Neural Network Based Alternative to Convolutional Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjextOooNPQAhWKUbwKHecwDmgQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1505.00393&usg=AFQjCNEJLTApjlKqYKQIizZLr3nS1Sy-fA)]
- ReSeg- A Recurrent Neural Network for Object Segmentation. [[pdf]](docs/2015/ReSeg- A Recurrent Neural Network for Object Segmentation.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj1-sbBoNPQAhXCfrwKHZH8DnQQFggnMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.07053&usg=AFQjCNF8WsGCR2nS5XYAShF_zzTfvd1ckg)]
- <b>Rethinking the Inception Architecture for Computer Vision</b>. [[pdf]](docs/2015/Rethinking the Inception Architecture for Computer Vision.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiRnMzcoNPQAhUENbwKHSxSATAQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1512.00567&usg=AFQjCNH8cDaqKtWdPI89vZv9MFeHTjlR4w)]
- <b>Semi-Supervised Learning with Ladder Networks</b>. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiPmrj4oNPQAhWJVbwKHbpjAB0QFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1507.02672&usg=AFQjCNHN95nVk-ZgIVniY-5O8P8niql8Pg)]
- Session-based Recommendations with Recurrent Neural Networks. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi2uPD7odPQAhVIfrwKHYjqAJsQFggjMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.06939&usg=AFQjCNHQCiJnwlyuU39SYkgDhP9lAckyIg)]
- <b>Skip-Thought Vectors</b>. [[pdf]](docs/2015/Skip-Thought Vectors.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiv7tXaotPQAhVKfrwKHUkID6wQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.06726&usg=AFQjCNGgfIfg5leG9gyRlO0EUjl-c-rYVQ)]
- [Spatial Transformer Networks.](http://blog.csdn.net/shaoxiaohu1/article/details/51809605) [[pdf]](docs/2015/Spatial Transformer Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiEgJz0otPQAhXHmZQKHXM3DJUQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.02025&usg=AFQjCNH5DcVI1dz_3sTqdgvi3rmITcGN7g)]
- <b>Training Very Deep Networks.</b> [[pdf]](docs/2015/Training Very Deep Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiMvvHuo9PQAhXDxbwKHZjSCtgQFggiMAA&url=http%3A%2F%2Farxiv.org%2Fabs%2F1507.06228&usg=AFQjCNHkQ_NfRPI9BQgrHI_wn2zFgOtrSA)]
- Tree-structured composition in neural networks without tree-structured architectures. [[pdf]](docs/2015/Tree-structured composition in neural networks without tree-structured architectures.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjl5e6MpNPQAhVGNrwKHdozBbwQFggtMAE&url=http%3A%2F%2Fceur-ws.org%2FVol-1583%2FCoCoNIPS_2015_paper_5.pdf&usg=AFQjCNFpO43q61p6ROBIFOx94CPr9EAdLQ)]

### Natural language process

- A Primer on Neural Network Models for Natural Language Processing. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjr-I3b-9LQAhVEVbwKHVo8A70QFggsMAE&url=http%3A%2F%2Fcs.biu.ac.il%2F~yogo%2Fnnlp.pdf&usg=AFQjCNEZEkggUYseGdLhpFy_iG5mBA3X9g)]
- A Unified Tagging Solution- Bidirectional LSTM Recurrent Neural Network with Word Embedding.  [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj-t_LG_NLQAhVES7wKHWTtCmIQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.00215&usg=AFQjCNECqO7dKUb1L7bkvFFR_8-hgPy52w)]
- Alternative structures for character-level RNNs. [[pdf]](docs/2015/Alternative structures for character-level RNNs.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiyx_iZ_dLQAhUBT7wKHUE0A38QFggqMAE&url=http%3A%2F%2Fwww.di.ens.fr%2F~bojanowski%2Fpapers%2Fbojanowski16alternative.pdf&usg=AFQjCNF0ds1vVOijyqtBX-g_s9x8OedIbg)]
- Ask Me Anything- Dynamic Memory Networks for Natural Language Processing. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiH8Kjf_dLQAhXIxLwKHU7QAb8QFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.07285&usg=AFQjCNFjdb3GPe1IrNPSh8zevJazf58JwQ)]
- BlackOut- Speeding up Recurrent Neural Network Language Models With Very Large Vocabularies. [[url](https://arxiv.org/abs/1511.06909)]
- <b>Character-Aware Neural Language Models.</b> [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjJ7JjA_9LQAhVDwLwKHbmaCskQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1508.06615&usg=AFQjCNG3RqYNgZfsn7zIez3SEzwB70cEKg)]
- Character-level Convolutional Networks for Text Classification. [[pdf]](docs/2015/Character-level Convolutional Networks for Text Classification.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiE5qTl_9LQAhUEWLwKHcHaDQgQFggsMAE&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5782-character-level-convolutional-networks-for-text-classification.pdf&usg=AFQjCNFInMceTBvIU8_8XmtKfoizKGpOVA)]
- <b>Deep Speech 2- End-to-End Speech Recognition in English and Mandarin.</b> [[pdf]](docs/2015/Deep Speech 2- End-to-End Speech Recognition in English and Mandarin.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwi5uvCDgdPQAhVFwLwKHSJ6B0MQFggvMAE&url=http%3A%2F%2Fjmlr.org%2Fproceedings%2Fpapers%2Fv48%2Famodei16.pdf&usg=AFQjCNFE5u2Xu81DH2gQUoyHVtC4AzLhYg)]
- <b>Distributed Representations of Sentences and Documents</b>. [[pdf]](docs/2015/Distributed Representations of Sentences and Documents.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjf2ZyrgtPQAhWJvrwKHTV4BqsQFgguMAE&url=http%3A%2F%2Fcs.stanford.edu%2F~quocle%2Fparagraph_vector.pdf&usg=AFQjCNESECVF_9eXAkAjfSqqHrqlxkVQgg)]
- Dynamic Capacity Networks. [[pdf]](docs/2015/Dynamic Capacity Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiN_Yj0gtPQAhVPQLwKHVz0BZwQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.07838&usg=AFQjCNFR0AEK2z-pT8ulDl98QWXP0M3fCw)]
- Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs. [[pdf]](docs/2015/Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjy35b6g9PQAhUDx7wKHULuChcQFggsMAE&url=https%3A%2F%2Fwww.aclweb.org%2Fanthology%2FD%2FD15%2FD15-1041.pdf&usg=AFQjCNHhOsMGNAY4FXq5-B9dDjy-OPBWvA)]
- Larger-Context Language Modeling. [[pdf]](docs/2015/Larger-Context Language Modeling.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjHlvWshNPQAhWLybwKHTiuB-0QFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.03729&usg=AFQjCNG88NnFeKSPKis1dVnVNYa0Tu50Gw)]
- Multi-task Sequence to Sequence Learning. [[pdf]](docs/2015/Multi-task Sequence to Sequence Learning.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiu7MbphdPQAhWDUrwKHeo3DO8QFggpMAE&url=http%3A%2F%2Fjan.stanford.edu%2Fpubs%2Fluong2016iclr_multi.pdf&usg=AFQjCNGYWAqWnjbi6p3ZXWe0hBcNMSWawA)]
- Natural Language Understanding with Distributed Representation. [[pdf]](docs/2015/Natural Language Understanding with Distributed Representation.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjhm4yThtPQAhWJVrwKHY-fDusQFggiMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.07916&usg=AFQjCNEXqHl1eNACFv-e99vq-omz4TcY_Q)]
- Neural Machine Translation of Rare Words with Subword Units. [[arxiv](https://arxiv.org/abs/1508.07909)]
- Neural Responding Machine for Short-Text Conversation. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiT-aOMntPQAhXHwbwKHXcqAzYQFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1503.02364&usg=AFQjCNETeT0aqPYSdo-fP-DYyl7WZg2BqQ)]
- Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Recurrent Neural Network. [[pdf]](docs/2015/Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Recurrent Neural Network.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwigxZnPntPQAhUCybwKHRJrCc8QFggiMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1510.06168&usg=AFQjCNEIDEbarhumVAtwYDPin-r5-10mSQ)]
- Reading Scene Text in Deep Convolutional Sequences. [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjnwcaJpY7RAhVnwlQKHdQhBMkQFggrMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.04395&usg=AFQjCNFwWEe1FlLYwTvy5JrYCme9M_QREA)]
- Recurrent Convolutional Neural Networks for Text Classification. [[pdf](https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=0ahUKEwip1u_yqpTRAhXGz1QKHUGDCc8QFggxMAI&url=http%3A%2F%2Fwww.aaai.org%2Focs%2Findex.php%2FAAAI%2FAAAI15%2Fpaper%2Fdownload%2F9745%2F9552&usg=AFQjCNFn9tI5wMb1f81hDQPHySE9C2OOpA)]
- Semi-supervised Sequence Learning. [[pdf]](docs/2015/Semi-supervised Sequence Learning.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwj28pOnodPQAhUJT7wKHb_eDpIQFggiMAA&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5949-semi-supervised-sequence-learning.pdf&usg=AFQjCNFi_8bOPu361mtaI13MWB_aHDlspg)]
- Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems. [[arxiv](https://arxiv.org/abs/1508.01745)]
- sense2vec - A Fast and Accurate Method for Word Sense Disambiguation In Neural Word Embeddings. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=4&cad=rja&uact=8&ved=0ahUKEwiQ_aHDodPQAhUITLwKHYP2B2kQFgg5MAM&url=https%3A%2F%2Fpdfs.semanticscholar.org%2F36f9%2F886ad1cb9ee3f66c5af0282ae7a3359b86b2.pdf&usg=AFQjCNE7oWW1uaAuK2skjRUnPXhykGFeMw)]
- Sequence Level Training with Recurrent Neural Networks. [[pdf]](docs/2015/Sequence Level Training with Recurrent Neural Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjEgIbnodPQAhUKyrwKHXJICVUQFgghMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.06732&usg=AFQjCNGEymvqFAIJnyEUAh0Ok7dImTDJjg)]
- Strategies for Training Large Vocabulary Neural Language Models. [[pdf]](docs/2015/Strategies for Training Large Vocabulary Neural Language Models.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjE1KCTo9PQAhXHwrwKHeTfDZ8QFggsMAE&url=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FP%2FP16%2FP16-1186.pdf&usg=AFQjCNGUJ0zFy2G4j9x9enwYuu2iTN5cig)]
- Teaching Machines to Read and Comprehend. [[pdf]](docs/2015/Teaching Machines to Read and Comprehend.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiu6Y2no9PQAhUJS7wKHYB-BjwQFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.03340&usg=AFQjCNEhq-W8rar0b08n_Vt3CSkeOFTJLw)]
- Towards Universal Paraphrastic Sentence Embeddings. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjM-u3Jo9PQAhUDbrwKHXETBuAQFggtMAE&url=http%3A%2F%2Fttic.uchicago.edu%2F~wieting%2Fwieting2016ICLR.pdf&usg=AFQjCNFMW6NpxCP9FMXpati4GbmkkCgPWQ)]
- Visualizing and Understanding Neural Models in NLP. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=0ahUKEwjszoDFpNPQAhWIxbwKHYlEAV0QFgg2MAI&url=https%3A%2F%2Fweb.stanford.edu%2F~jurafsky%2Fpubs%2Fvisualizing16.pdf&usg=AFQjCNECNXN2Cf42XcZokv2o5sE6RNM41Q)]

### Adversarial network

- Autoencoding beyond pixels using a learned similarity metric. [[arxiv](https://arxiv.org/abs/1512.09300)]
- [LAPGAN] Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks. [[arxiv](https://arxiv.org/abs/1506.05751)]
- Generative Image Modeling Using Spatial LSTMs. [[arxiv](https://arxiv.org/abs/1506.03478)]
- Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks. [[arxiv](https://arxiv.org/abs/1511.06390)]
- [DCGAN] <b>Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</b>. [[pdf]](docs/2015/Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.pdf) [[arxiv](https://arxiv.org/abs/1511.06434)] [[code](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjjzcaIpqDRAhVKw1QKHZ6eDxEQFggrMAE&url=https%3A%2F%2Fgithub.com%2FNewmu%2Fdcgan_code&usg=AFQjCNFLjTPZgeru6CC8JHyS327QIW7EEg)]

### Attention and memory

- Attention with Intention for a Neural Network Conversation Model. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj--cv5_dLQAhUJv7wKHenpD3EQFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1510.08565&usg=AFQjCNHP09eh3A7Ys6D6bqDbhyb9SAuixQ)]
- <b>End-To-End Memory Networks.</b> [[arxiv](https://arxiv.org/abs/1503.08895)]
- <b>Show, Attend and Tell- Neural Image Caption Generation with Visual Attention</b>. [[pdf]](docs/2015/Show, Attend and Tell- Neural Image Caption Generation with Visual Attention.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiwwZmqotPQAhWCvbwKHZFwD9IQFggwMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1502.03044&usg=AFQjCNECNcNjKjJkda1TxlcPtNO4dbTiEw)]
- Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation. [[arxiv](https://arxiv.org/abs/1512.04650)] 
- Ask Me Anything: Dynamic Memory Networks for Natural Language Processing. [[arxiv](https://arxiv.org/abs/1506.07285)]
- <b>A Neural Attention Model for Sentence Summarization</b>. [[pdf](docs/2015/A Neural Attention Model for Sentence Summarization.pdf)] [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiJnNOM-9LQAhVGWrwKHTH3BFAQFggiMAA&url=https%3A%2F%2Fwww.aclweb.org%2Fanthology%2FD%2FD15%2FD15-1044.pdf&usg=AFQjCNFw54b4APRJXCmpk2Yf0ttsATDZNA)]
- [VAE with attention] DRAW: A Recurrent Neural Network For Image Generation. [[arxiv](https://arxiv.org/abs/1502.04623)] [[code](https://github.com/ericjang/draw)]
- <b>Effective Approaches to Attention-based Neural Machine Translation</b>. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjhkfGlotjQAhXFULwKHTzhA1YQFggmMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1508.04025&usg=AFQjCNHOjFZaEvp3YSwQTEhrgmmLW6ER8g)]
- End-to-End Attention-based Large Vocabulary Speech Recognition. [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwi7y9Dbvo7RAhVF0FQKHa3SCAoQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1508.04395&usg=AFQjCNE-iJp1IdJm552na5qzcFJNQ85cxA)]

### Transfer learning

- Transfer learning using computational intelligence: A survey. [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiy2_T1tY7RAhXBwFQKHXTrAUEQFggqMAE&url=https%3A%2F%2Fpdfs.semanticscholar.org%2F21bb%2Fec954226c5fdf53560cb072188a18051683c.pdf&usg=AFQjCNHTlj0iUN_xNVabR1ZRsyiEgkJmFg)]

### Deep reinforcement learning

- ADAAPT: A Deep Architecture for Adaptive Policy Transfer from Multiple Sources, J. Rajendran et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1510.02879)]
- <b>Action-Conditional Video Prediction using Deep Networks in Atari Games</b>, J. Oh et al., *NIPS*.  [[arxiv](http://arxiv.org/abs/1507.08750)]
- Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning. [[arxiv](https://arxiv.org/abs/1511.06342)]
- [DDPG] Continuous control with deep reinforcement learning. [[arxiv](https://arxiv.org/abs/1509.02971)]
- [NAF] Continuous Deep Q-Learning with Model-based Acceleration. [[arxiv](https://arxiv.org/abs/1603.00748)]
- <b>Dueling Network Architectures for Deep Reinforcement Learning</b>, Z. Wang et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1511.06581)]
- Deep Reinforcement Learning with an Action Space Defined by Natural Language, J. He et al., *arXiv*. [[arxiv](http://arxiv.org/abs/1511.04636)]
- <b>Deep Reinforcement Learning with Double Q-learning</b>, H. van Hasselt et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1509.06461)]
- <b>Deep Recurrent Q-Learning for Partially Observable MDPs</b>, M. Hausknecht and P. Stone, *arXiv*.  [[arxiv](http://arxiv.org/abs/1507.06527)]
- DeepMPC: Learning Deep Latent Features for Model Predictive Control, I. Lenz, et al., *RSS*.  [[url](http://deepmpc.cs.cornell.edu/DeepMPC.pdf)]
- <b>Deterministic Policy Gradient Algorithms</b>, D. Silver et al., *ICML*.  [[url](http://jmlr.org/proceedings/papers/v32/silver14.pdf)]
- Dueling Network Architectures for Deep Reinforcement Learning. [[arxiv](https://arxiv.org/abs/1511.06581)]
- <b>End-to-End Training of Deep Visuomotor Policies</b>, S. Levine et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1504.00702)]
- Giraffe: Using Deep Reinforcement Learning to Play Chess, M. Lai, *arXiv*.  [[arxiv](http://arxiv.org/abs/1509.01549)]
- Generating Text with Deep Reinforcement Learning, H. Guo, *arXiv*.  [[arxiv](http://arxiv.org/abs/1510.09202)]
- How to Discount Deep Reinforcement Learning: Towards New Dynamic Strategies, V. François-Lavet et al., *NIPS Workshop*.  [[arxiv](http://arxiv.org/abs/1512.02011)]
- <b>Human-level control through deep reinforcement learning</b>, V. Mnih et al., *Nature*.  [[url](http://www.nature.com/nature/journal/v518/n7540/pdf/nature14236.pdf)]
- <b>Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models</b>, B. C. Stadie et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1507.00814)]
- Learning Simple Algorithms from Examples, W. Zaremba et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1511.07275)]
- <b>Language Understanding for Text-based Games Using Deep Reinforcement Learning</b>, K. Narasimhan et al., *EMNLP*.  [[url](http://people.csail.mit.edu/karthikn/pdfs/mud-play15.pdf)]
- <b>Learning Continuous Control Policies by Stochastic Value Gradients</b>, N. Heess et al., *NIPS*.  [[url](http://papers.nips.cc/paper/5796-learning-continuous-control-policies-by-stochastic-value-gradients.pdf)]
- Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences, H. Mei et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1506.04089)]
- Learning Deep Neural Network Policies with Continuous Memory States, M. Zhang et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1507.01273)]
- Multiagent Cooperation and Competition with Deep Reinforcement Learning, A. Tampuu et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1511.08779)]
- Maximum Entropy Deep Inverse Reinforcement Learning, M. Wulfmeier et al., *arXiv*. [[arxiv](http://arxiv.org/abs/1507.04888)]
- <b>Massively Parallel Methods for Deep Reinforcement Learning</b>, A. Nair et al., *ICML Workshop*.  [[url](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/gorila.pdf)]
- Memory-based control with recurrent neural networks, N. Heess et al., *NIPS Workshop*.  [[arxiv](http://arxiv.org/abs/1512.04455)]
- On Learning to Think- Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models.  [[arxiv](https://arxiv.org/pdf/1511.09249)]
- Playing Atari with Deep Reinforcement Learning. [[arxiv](https://arxiv.org/abs/1312.5602)]
- Recurrent Reinforcement Learning: A Hybrid Approach, X. Li et al., *arXiv*. [[arxiv](http://arxiv.org/abs/1509.03044)]
- Reinforcement Learning Neural Turing Machines. [[arxiv](https://arxiv.org/abs/1505.00521)]
- Strategic Dialogue Management via Deep Reinforcement Learning, H. Cuayáhuitl et al., *NIPS Workshop*. [[arxiv](http://arxiv.org/abs/1511.08099)]
- Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control, F. Zhang et al., *arXiv*. [[arxiv](http://arxiv.org/abs/1511.03791)]
- <b>Trust Region Policy Optimization</b>, J. Schulman et al., *ICML*. [[url](http://jmlr.org/proceedings/papers/v37/schulman15.pdf)]
- Universal Value Function Approximators, T. Schaul et al., *ICML*. [[url](http://schaul.site44.com/publications/uvfa.pdf)]
- Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning, S. Mohamed and D. J. Rezende, *arXiv*. [[arxiv](http://arxiv.org/abs/1509.08731)]

## 2014

### Deep Learning

- A Convolutional Neural Network for Modelling Sentences. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiDtNqj4tDQAhUIfrwKHaM1CsoQFggiMAA&url=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FP14-1062&usg=AFQjCNGpQydUVX0JP-bAqqspIMdZmG6TIw)]
- Automatic Construction and Natural-Language Description of Nonparametric Regression Models[[pdf]](docs/2014/Automatic Construction and Natural-Language Description of Nonparametric Regression Models(2014).pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj3xcWb49DQAhWIw7wKHSXFCfEQFggrMAE&url=http%3A%2F%2Fwww.aaai.org%2Focs%2Findex.php%2FAAAI%2FAAAI14%2Fpaper%2FviewFile%2F8240%2F8564&usg=AFQjCNFyni0wwo38CsLRVtSPMm6BlL7QpA)]
- Convolutional Neural Networks for Sentence Classification. [[pdf]](docs/2014/Convolutional Neural Networks for Sentence Classification.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwizssq549DQAhXKv7wKHQVqBY0QFgguMAE&url=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FD14-1181&usg=AFQjCNGcdltQiLIWrZRVlmgqIMEQ4p39Mg)]
- <b>Distributed Representations of Sentences and Documents Generating Distribution</b>. [[pdf]](docs/2014/Distributed Representations of Sentences and Documents Generating Distribution.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiulvPb49DQAhUGbrwKHeFRAlsQFggiMAA&url=http%3A%2F%2Fcs.stanford.edu%2F~quocle%2Fparagraph_vector.pdf&usg=AFQjCNESECVF_9eXAkAjfSqqHrqlxkVQgg)]
- Dropout: A Simple Way to Prevent Neural Networks from Overfitting. [[pdf](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)]
- Effective Use of Word Order for Text Categorization with Convolutional Neural Networks. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiIl7qS5NDQAhVD2LwKHct_CVYQFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1412.1058&usg=AFQjCNHDPOYHMKWIhirkznqnLq_mw4CqMQ)]
- <b>Generative Adversarial Nets.</b> [[pdf]](docs/2014/Generative Adversarial Nets.pdf) [[arxiv](https://arxiv.org/abs/1406.2661)] [[code](https://github.com/goodfeli/adversarial)]
- [GoogLeNet] [Going Deeper with Convolutions](http://blog.csdn.net/u014114990/article/details/50370446). [[pdf](docs/2014/Going Deeper with Convolutions.pdf)] [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjHpOvi5NDQAhUCxLwKHU4BBM8QFgguMAE&url=https%3A%2F%2Fwww.cs.unc.edu%2F~wliu%2Fpapers%2FGoogLeNet.pdf&usg=AFQjCNHSEJVb0PWLBIG-Y-zWh9gRv9ehBQ)]
- Grammar as a Foreign Language. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwitq9CI5dDQAhXCu7wKHTUIBiAQFggpMAE&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5635-grammar-as-a-foreign-language.pdf&usg=AFQjCNELENZf9OsnZ6q0LexQYcbjCHBv0w)]
- Learning Longer Memory in Recurrent Neural Networks. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiOkqOu5dDQAhVFa7wKHc7pCdgQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1412.7753&usg=AFQjCNEz4_vREocEuriflTVFg0GrMmaqfw)]
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](http://www.zmonster.me/notes/phrase_representation_using_rnn_encoder_decoder.html). [[arxiv](https://arxiv.org/abs/1406.1078)]
- Learning to Execute. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiVoZuO5tDQAhWJwLwKHVouD40QFggdMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1410.4615&usg=AFQjCNEXYyZHLwwTzovP3pHsWa_jxvWvEQ)]
- Machine learning for targeted display advertising: transfer learning in action. [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiZr8H5uY7RAhXJq1QKHUocC64QFggfMAA&url=http%3A%2F%2Fdstillery.com%2Fwp-content%2Fuploads%2F2014%2F05%2FMachine-learning_target-display.pdf&usg=AFQjCNGDcM3pAUJ9-ZL7i0ujCUIWHenABQ)]
- [Network In Network](http://blog.csdn.net/hjimce/article/details/50458190). [[pdf](docs/2014/Network In Network.pdf)] [[arxiv](https://arxiv.org/abs/1312.4400)]
- <b>Neural Turing Machines.</b> [[pdf]](docs/2014/Neural Turing Machines.pdf) [[arxiv](https://arxiv.org/abs/1410.5401)]
- On the Properties of Neural Machine Translation- Encoder-Decoder Approaches. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjqtZDc59DQAhUGyrwKHbhDBLUQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1409.1259&usg=AFQjCNG6_CJ8ZYMv5sx4K59mRIPpHlL-Yg)]
- On Using Very Large Target Vocabulary for Neural Machine Translation. [[pdf]](docs/2014/On Using Very Large Target Vocabulary for Neural Machine Translation.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiSle7659DQAhULTbwKHfaiBsoQFggsMAE&url=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FP15-1001&usg=AFQjCNFUabHMFw5X9gjg26vjoDljEd4s_g)]
- [OverFeat] [OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks.](http://blog.csdn.net/whiteinblue/article/details/43374195) [[arxiv](https://arxiv.org/abs/1312.6229)]
- Reading Text in the Wild with Convolutional Neural Networks. [[pdf]](docs/2015/Reading Text in the Wild with Convolutional Neural Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiBlcrmn9PQAhXGW7wKHa6VAEwQFggsMAE&url=https%3A%2F%2Fwww.robots.ox.ac.uk%2F~vgg%2Fpublications%2F2016%2FJaderberg16%2Fjaderberg16.pdf&usg=AFQjCNG2V55rN1HOyhtSMLcHAyiuAYFl3A)]
- Recurrent Neural Network Regularization. [[pdf]](docs/2014/Recurrent Neural Network Regularization.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwih-O696NDQAhXETLwKHYycC7gQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1409.2329&usg=AFQjCNFVduu07csNxH2drGk4FxsNpJ6pmA)]
- <b>Sequence to Sequence Learning with Neural Networks</b>. [[pdf]](docs/2014/Sequence to Sequence Learning with Neural Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiJlZvX6NDQAhXIe7wKHSPgDcUQFggiMAA&url=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5346-sequence-to-sequence-learning-with-neural-networks.pdf&usg=AFQjCNFmjsgkpjcnH0BXlGdwER5uhHq7hg)]
- <b>Show and Tell: A Neural Image Caption Generator.</b>[[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjL6s6Xn47RAhVlqVQKHaynDI4QFggnMAE&url=%68%74%74%70%73%3a%2f%2f%61%72%78%69%76%2e%6f%72%67%2f%70%64%66%2f%31%34%31%31%2e%34%35%35%35&usg=AFQjCNEawcm4ZOK9ZVIgCjylPb2HY1UOug)]
- <b>Towards end-to-end speech recognition with recurrent neural networks.</b> [[pdf](http://jmlr.org/proceedings/papers/v32/graves14.pdf)]
- [VGG14] [Very Deep Convolutional Networks for Large-Scale Image Recognition](http://www.cnblogs.com/xuanyuyt/p/5743758.html). [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjojM766NDQAhUGE7wKHV41BCkQFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1409.1556&usg=AFQjCNGCj1kt2G50dIxnPbwC-QmXnL7Mcg)]
- What Regularized Auto-Encoders Learn from the Data. [[pdf]](docs/2014/What Regularized Auto-Encoders Learn from the Data.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi_3fWb6dDQAhVDOrwKHQHWBzQQFggdMAA&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1211.4246&usg=AFQjCNFQTNK_88872IDR0e56SV0L2z80eQ)]

### Attention and memory

- <b>Memory Networks.</b> [[arxiv](https://arxiv.org/abs/1410.3916)]
- Multiple Object Recognition with Visual Attention. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjW5KK95tDQAhVEbbwKHU3yC40QFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1412.7755&usg=AFQjCNEdl2iMZSeK_mYsIKs8HXm4yI6zKQ)]
- <b>Neural Machine Translation by Jointly Learning to Align and Translate</b>. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwic1dL-5tDQAhUIv7wKHZN5BawQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1409.0473&usg=AFQjCNGh-Bsjuf_Yiaf4a6aYfAZcepRFUQ)]
- Recurrent Models of Visual Attention. [[pdf]](docs/2014/Recurrent Models of Visual Attention.pdf) [[url](https://papers.nips.cc/paper/5542-recurrent-models-of-visual-attention.pdf)]

### Deep Reinforcement Learning

- Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning, X. Guo et al., *NIPS*.[[url](http://papers.nips.cc/paper/5421-deep-learning-for-real-time-atari-game-play-using-offline-monte-carlo-tree-search-planning.pdf)]

## 2013

### Deep Learning

- Adaptive dropout for training deep neural networks. [[pdf]](docs/2013/Adaptive dropout for training deep neural networks.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjDrbLe0NDQAhULrFQKHXfIBOcQFgggMAA&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5032-adaptive-dropout-for-training-deep-neural-networks.pdf&usg=AFQjCNEIvLpW_VwelyHjOxQ7up1Wc4djkA)]
- [VAE] Auto-Encoding Variational Bayes. [[arxiv](https://arxiv.org/abs/1312.6114)]
- Better Mixing via Deep Representations. [[pdf]](docs/2013/Yoshua Bengio.Better Mixing via Deep Representations.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj629740dDQAhUmi1QKHRjaB4AQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1207.4404&usg=AFQjCNEVC3VegGSWQXm-XJvWXOjjlk1VIA)]
- Deep Fisher Networks for Large-Scale Image Classification. [[pdf]](docs/2013/Deep Fisher Networks for Large-Scale Image Classification.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwifnNeg0tDQAhWpsVQKHU3wB4sQFgggMAA&url=https%3A%2F%2Fwww.robots.ox.ac.uk%2F~vgg%2Fpublications%2F2013%2FSimonyan13b%2Fsimonyan13b.pdf&usg=AFQjCNEixGKMTXtLPadNICunAuLHvv-iog)]
- Deep Learning of Representations-looking forward. [[url]](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiVocvG0tDQAhWLhVQKHRcvAIcQFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1305.0445&usg=AFQjCNFmv3e_Pd6z34Er4V3zvUqO77QXog)]
- Deep Neural Networks for Object Detection. [[pdf]](docs/2013/Deep Neural Networks for Object Detection.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwie1brk0tDQAhWhxlQKHVSQACIQFggiMAA&url=https%3A%2F%2Fpdfs.semanticscholar.org%2F713f%2F73ce5c3013d9fb796c21b981dc6629af0bd5.pdf&usg=AFQjCNF79vro3uwWMO53Sqh9Imh62uCl_A)]
- Dropout Training as Adaptive Regularization. [[pdf]](docs/2013/Dropout Training as Adaptive Regularization.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjmzZCU09DQAhXpz1QKHYuNC1AQFgguMAE&url=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4882-dropout-training-as-adaptive-regularization.pdf&usg=AFQjCNEChKFYrerSVjmcTeUW8JdtiLisGw)]
- <b>Efficient Estimation of Word Representations in Vector Space</b>. [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjYx_TI09DQAhXihFQKHcNpBeQQFgggMAA&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1301.3781&usg=AFQjCNFo6E4qrQLPJrMm4O4UzOEivh0Crw)]
- Exploiting Similarities among Languages for Machine Translation. [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj245_009DQAhWEjFQKHSLHDTkQFggsMAE&url=http%3A%2F%2Fresearch.google.com%2Fpubs%2Farchive%2F44931.pdf&usg=AFQjCNEIiCd3WIURIXZY0fch73RrpgnhvQ)]
- Generalized Denoising Auto-Encoders as Generative Models. [[pdf]](docs/2013/Generalized Denoising Auto-Encoders as Generative Models.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjl1OK-1dDQAhWEhFQKHTKeDE8QFgggMAA&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5023-generalized-denoising-auto-encoders-as-generative-models.pdf&usg=AFQjCNHPSme5uHUkCwRbI5Hv1OdqGjn4Xw)]
- Learning a Deep Compact Image Representation for Visual Tracking. [[pdf]](docs/2013/Learning a Deep Compact Image Representation for Visual Tracking.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwi3zYW01tDQAhWIwFQKHUmCCnMQFggqMAE&url=http%3A%2F%2Fwinsty.net%2Fpapers%2Fdlt.pdf&usg=AFQjCNFUQTWp6bQNt1AhJ50sXR7Gj-azAA)]
- <b>Learning Hierarchical Features for Scene Labeling</b>. [[pdf]](docs/2013/Learning Hierarchical Features for Scene Labeling.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjip9nP1tDQAhWs0FQKHVE3CiUQFggiMAA&url=http%3A%2F%2Fyann.lecun.com%2Fexdb%2Fpublis%2Fpdf%2Ffarabet-pami-13.pdf&usg=AFQjCNGaHp1t2JKhTOWjhqAzmWrcMbnQ-A)]
- Learning Multi-level Sparse Representations. [[pdf]](docs/2013/Learning Multi-level Sparse Representations.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjG5_uX19DQAhVCrlQKHSiqB64QFggiMAA&url=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5076-learning-multi-level-sparse-representations.pdf&usg=AFQjCNGnJjQja7ddxoLTaC6Zr_VR4tqKaw)]
- <b>Maxout Networks</b>. [[pdf]](docs/2013/Maxout Networks.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj5vpjM19DQAhUos1QKHZ6zAQcQFggnMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1302.4389&usg=AFQjCNHCC8d-MyLhvu0kw2dsmCZHa17OXA)]
- No More Pesky Learning Rates. [[pdf]](docs/2013/No More Pesky Learning Rates.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjby9Lu19DQAhXCilQKHVuJA0MQFggdMAA&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1206.1106&usg=AFQjCNFM0JupBcHvTGZck8kaO4xEvcYXdg)]
- On autoencoder scoring. [[pdf]](docs/2013/On autoencoder scoring.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjAnuio2NDQAhWHh1QKHf3PAXIQFggdMAA&url=http%3A%2F%2Fwww.jmlr.org%2Fproceedings%2Fpapers%2Fv28%2Fkamyshanska13.pdf&usg=AFQjCNGNvTTTRcMXCdGjbhaekXcIqEMjOw)]
- On the difficulty of training recurrent neural networks. [[pdf]](docs/2013/On the difficulty of training recurrent neural networks(2013).pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwj3z4LN2NDQAhXjjlQKHSPhCaAQFgggMAA&url=http%3A%2F%2Fwww.jmlr.org%2Fproceedings%2Fpapers%2Fv28%2Fpascanu13.pdf&usg=AFQjCNEATfq_Z8jFkNJ_zO566QBDMyyaSw)]
- On the importance of initialization and momentum in deep learning.[[pdf]](docs/2013/On the importance of initialization and momentum in deep learning.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwifhdjp2NDQAhXCq1QKHarVB2cQFggdMAA&url=http%3A%2F%2Fwww.cs.toronto.edu%2F~hinton%2Fabsps%2Fmomentum.pdf&usg=AFQjCNF_On1gl-3iNj7fJ6EYSrP1RBckPg)]
- Regularization of Neural Networks using DropConnect. [[pdf]](docs/2013/Regularization of Neural Networks using DropConnect.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjL_5GH2dDQAhVhq1QKHVzuBzIQFggiMAA&url=http%3A%2F%2Fwww.matthewzeiler.com%2Fpubs%2Ficml2013%2Ficml2013.pdf&usg=AFQjCNFy6eyEr7XS251AkptfvV537UPQAA)]
- <b>Representation Learning A Review and New Perspectives</b>. [[pdf]](docs/2013/Representation Learning A Review and New Perspectives.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwj9zK6s2tDQAhWjjVQKHXq1A5oQFggiMAA&url=http%3A%2F%2Fwww.cl.uni-heidelberg.de%2Fcourses%2Fws14%2Fdeepl%2FBengioETAL12.pdf&usg=AFQjCNEQI9Rst49wWNFRe1TG9nZscxS2QQ)]
- [RCNN] [Rich feature hierarchies for accurate object detection and semantic segmentation.](http://blog.csdn.net/u011534057/article/details/51218218) [[arxiv](https://arxiv.org/abs/1311.2524)]
- Scaling up Spike-and-Slab Models for Unsupervised Feature Learning. [[pdf]](docs/2013/Scaling up Spike-and-Slab Models for Unsupervised Feature Learning.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjb2dzP2tDQAhXKyVQKHSxGCB8QFggqMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1201.3382&usg=AFQjCNEgFUQgcIZqlcsOnuFAJwCiid4_QQ)]
- <b>Speech Recognition with Deep Recurrent Neural Networks.</b> [[url](https://arxiv.org/abs/1303.5778)]
- Stochastic Pooling for Regularization of Deep Convolutional Neural Networks. [[pdf]](docs/2013/Stochastic Pooling for Regularization of Deep Convolutional Neural Networks.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiB8sbr2tDQAhWFiFQKHQa_CosQFgggMAA&url=http%3A%2F%2Fwww.matthewzeiler.com%2Fpubs%2Ficlr2013%2Ficlr2013.pdf&usg=AFQjCNGBzD7QvKjhVqEfTqx52q3Fgvz3IA)]
- [ZFNet] <b>Visualizing and Understanding Convolutional Networks</b>. [[pdf]](docs/2013/Visualizing and Understanding Convolutional Networks.pdf) [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjkzKeI29DQAhXCqlQKHZMCDRAQFggiMAA&url=http%3A%2F%2Fwww.cs.nyu.edu%2F~fergus%2Fpapers%2FzeilerECCV2014.pdf&usg=AFQjCNFRXYdMaGmpHegQP_bccZWSKDgmlw)]

### Deep Reinforcement Learning

- <b>Playing Atari with Deep Reinforcement Learning</b>, V. Mnih et al., *NIPS Workshop*. [[url](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)]

# Courses

* [Stanford] [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)
* [CUHK] [ELEG 5040: Advanced Topics in Signal Processing(Introduction to Deep Learning)](https://piazza.com/cuhk.edu.hk/spring2015/eleg5040/home)
* [Stanford] [CS224d: Deep Learning for Natural Language Processing](http://cs224d.stanford.edu/)
* [Oxford] [Deep Learning by Prof. Nando de Freitas](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/)
* [NYU] [Deep Learning by Prof. Yann LeCun](http://cilvr.cs.nyu.edu/doku.php?id=courses:deeplearning2014:start)
* [Berkeley] [CS294: Deep Reinforcement Learning](http://rll.berkeley.edu/deeprlcourse/)

# Books

* [Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville](http://www.deeplearningbook.org/), [[zh](https://github.com/exacity/deeplearningbook-chinese)]
* [Neural Networks and Deep Learning by Michael Nielsen](http://neuralnetworksanddeeplearning.com/)
* [Deep Learning Tutorial by LISA lab, University of Montreal](http://deeplearning.net/tutorial/deeplearning.pdf)
* [神经网络与深度学习](https://nndl.github.io/)

# Videos

* Talks
  * [Deep Learning, Self-Taught Learning and Unsupervised Feature Learning By Andrew Ng](https://www.youtube.com/watch?v=n1ViNeWhC24)
  * [Recent Developments in Deep Learning By Geoff Hinton](https://www.youtube.com/watch?v=vShMxxqtDDs)
  * [The Unreasonable Effectiveness of Deep Learning by Yann LeCun](https://www.youtube.com/watch?v=sc-KbuZqGkI)
  * [Deep Learning of Representations by Yoshua bengio](https://www.youtube.com/watch?v=4xsVFLnHC_0)
* Courses
  * [Deep Learning Course – Nando de Freitas@Oxford](http://www.computervisiontalks.com/tag/deep-learning-course/)
  * [吴立德 《深度学习课程》](http://list.youku.com/albumlist/show?id=21508721&ascending=1&page=1)
  
# Software

* Apache Singa: Singa is an Apache Incubating project for developing an open source deep learning library. [[Web](http://singa.incubator.apache.org/en/index.html)]
* Caffe: Deep learning framework by the BVLC [[Web](http://caffe.berkeleyvision.org/)]
* CNTK:The Microsoft Cognitive Toolkit. [[Web](https://github.com/Microsoft/CNTK)]
* Deepgaze: A computer vision library for human-computer interaction based on CNNs [[Web](https://github.com/mpatacchiola/deepgaze)]
* Deeplearning4J: Neural Net Platform. [[Web](https://github.com/deeplearning4j/deeplearning4j)]
* Keras: Deep Learning library for Theano and TensorFlow. [[Web](https://keras.io/)]
* MatConvNet: CNNs for MATLAB [[Web](http://www.vlfeat.org/matconvnet/)]
* MXNet: A flexible and efficient deep learning library for heterogeneous distributed systems with multi-language support [[Web](http://mxnet.io/)]
* PaddlePaddle (PArallel Distributed Deep LEarning) is an easy-to-use, efficient, flexible and scalable deep learning platform. [[Web](http://www.paddlepaddle.org/)]
* Tensorflow: An open source software library for numerical computation using data flow graph by Google [[Web](https://www.tensorflow.org/)]
* Theano: Mathematical library in Python, maintained by LISA lab [[Web](http://deeplearning.net/software/theano/)]
  * Theano-based deep learning libraries: [[Pylearn2](http://deeplearning.net/software/pylearn2/)],
* Torch7: Deep learning library in Lua, used by Facebook and Google Deepmind [[Web](http://torch.ch/)]
  * Torch-based deep learning libraries: [[torchnet](https://github.com/torchnet/torchnet)],
 [[Blocks](https://github.com/mila-udem/blocks)], [[Keras](http://keras.io/)], [[Lasagne](https://github.com/Lasagne/Lasagne)]
