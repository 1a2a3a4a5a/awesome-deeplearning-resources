## 2015

### Deep learning

- A Diversity-Promoting Objective Function for Neural Conversation Models. [[pdf](docs/2015/A Diversity-Promoting Objective Function for Neural Conversation Models.pdf)] [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjghNPo-tLQAhULWLwKHZ6bB5sQFggsMAE&url=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FN16-1014&usg=AFQjCNE-WkcrMlvb2VudgN1271pPAV-ALg)]
- A Neural Algorithm of Artistic Style. [[arxiv](https://arxiv.org/abs/1508.06576)] [[code](https://github.com/titu1994/Neural-Style-Transfer)]
- A Neural Conversational Model. [[pdf]](docs/2015/A Neural Conversational Model.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjsnJOo-9LQAhXITLwKHb6IDjYQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.05869&usg=AFQjCNG8O97sWinlNfkyfEgPysuic8pXBA)]
- A Neural Network Approach to Context-Sensitive Generation of Conversational Responses. [[pdf]](docs/2015/A Neural Network Approach to Context-Sensitive Generation of Conversational Responses.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwi6sfPF-9LQAhVKVbwKHaKjDM8QFggsMAE&url=http%3A%2F%2Fwww-etud.iro.umontreal.ca%2F~sordonia%2Fpdf%2Fnaacl15.pdf&usg=AFQjCNFXJpaki2cwwGyTDAFnKKAFWsIoMA)]
- A Roadmap towards Machine Intelligence. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwivxdj8-9LQAhWBWbwKHaw1AgMQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.08130&usg=AFQjCNGL1YXbBqtEbePteiKtLdRpJMGsbw)]
- A Survey- Time Travel in Deep Learning Space- An Introduction to Deep Learning Models and How Deep Learning Models Evolved from the Initial Ideas. [[pdf]](docs/2015/A Survey- Time Travel in Deep Learning Space- An Introduction to Deep Learning Models and How Deep Learning Models Evolved from the Initial Ideas.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiTsdSu_NLQAhUKwbwKHYbBDRkQFggdMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1510.04781&usg=AFQjCNE77qGAxyoLWSDJepQsdH-dhmdLsQ)]
- [ADAM] <b>Adam: A Method for Stochastic Optimization</b>. [[pdf]](docs/2015/ADAM- A METHOD FOR STOCHASTIC OPTIMIZATION(2015).pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjNj9nq_NLQAhWBTrwKHRAYCNsQFggtMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1412.6980&usg=AFQjCNGoWw08vLoxCHTHcXPc4Y-jyOciXw)]
- <b>An Empirical Exploration of Recurrent Network Architectures.</b> [[pdf]](docs/2015/An Empirical Exploration of Recurrent Network Architectures(2015).pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjb_4HB_dLQAhXLXrwKHZohAl8QFgggMAA&url=http%3A%2F%2Fjmlr.org%2Fproceedings%2Fpapers%2Fv37%2Fjozefowicz15.pdf&usg=AFQjCNF0S7PLOOFJAsnaVD4GHptHN6D6JA)]
- [Batch Normalization] [Batch Normalization- Accelerating Deep Network Training by Reducing Internal Covariate Shift.](http://blog.csdn.net/happynear/article/details/44238541)  [[arxiv](https://arxiv.org/abs/1502.03167)]
- Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj73Kqm_9LQAhUEv7wKHYAkDcoQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1507.04808&usg=AFQjCNG63pfd4i9Wz_nj6FEyOYWslBdl-g)]
- Correlational Neural Networks. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjo5rn6_9LQAhUKebwKHe-LBuEQFggdMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1504.07225&usg=AFQjCNHzdHZ0b2ZoxS5bpmxh5rsghbSw2Q)]
- Deconstructing the Ladder Network Architecture. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiOjJadgNPQAhWJWrwKHdsoBs8QFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.06430&usg=AFQjCNG7yS2esOcnwWBLTCekAMofapfSOg)]
- Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding. [[arxiv](https://arxiv.org/abs/1510.00149)]
- Deep Knowledge Tracing. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjh4Nu3gNPQAhUHbbwKHZM6DAkQFggiMAA&url=https%3A%2F%2Fweb.stanford.edu%2F~cpiech%2Fbio%2Fpapers%2FdeepKnowledgeTracing.pdf&usg=AFQjCNGMGxC1N0jAosfrPXtAp-4Y0ctTXw)]
- [ResNet] [Deep Residual Learning for Image Recognition](http://blog.csdn.net/cv_family_z/article/details/50328175). [[pdf]](docs/2015/Deep Residual Learning for Image Recognition.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjL2pzjgNPQAhVBxLwKHfHgBKgQFgguMAE&url=http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016%2Fpapers%2FHe_Deep_Residual_Learning_CVPR_2016_paper.pdf&usg=AFQjCNFGFwwaDLEa7-LDpSTqyUv107yaEg)]
- [ResNet] <b>Delving Deep into Rectifiers- Surpassing Human-Level Performance on ImageNet Classification</b>. [[pdf]](docs/2015/Delving Deep into Rectifiers- Surpassing Human-Level Performance on ImageNet Classification(2015).pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiyssepgdPQAhXLwLwKHSttBuoQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1502.01852&usg=AFQjCNECb3XvSFc_BHFAjE-j1BIst-BMXw)]
- <b>Distilling the Knowledge in a Neural Network</b>. [[pdf]](docs/2015/Distilling the Knowledge in a Neural Network.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjutISLgtPQAhVKbbwKHet8DK4QFgguMAE&url=https%3A%2F%2Fwww.cs.toronto.edu%2F~hinton%2Fabsps%2Fdistillation.pdf&usg=AFQjCNGI14ldA9QhBoMO-4vT-qfrBQrsZA)]
- Dropout as a Bayesian Approximation- Representing Model Uncertainty in Deep Learning. [[url](https://arxiv.org/pdf/1506.02142)]
- Effective LSTMs for Target-Dependent Sentiment Classification. [[arxiv](https://arxiv.org/abs/1512.01100)]
- <b>Hierarchical Recurrent Neural Network for Skeleton Based Action Recognition.</b> [[url](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Du_Hierarchical_Recurrent_Neural_2015_CVPR_paper.pdf)]
- Inside-Outside Net- Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks. [[pdf]](docs/2015/Inside-Outside Net- Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj99o-ThNPQAhUMe7wKHaJZAs0QFggvMAE&url=http%3A%2F%2Fimage-net.org%2Fchallenges%2Ftalks%2Fion-coco-talk-bell2015.pdf&usg=AFQjCNFUVYf-MUBT2BKQPsrBLTDlzFt5PA)]
- Learning Simple Algorithms from Examples. [[pdf]](docs/2015/Learning Simple Algorithms from Examples.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj_7vPWhNPQAhUJgLwKHWC1A7gQFggvMAE&url=http%3A%2F%2Fjmlr.org%2Fproceedings%2Fpapers%2Fv48%2Fzaremba16.pdf&usg=AFQjCNEQlbOwzlKS6eUdVuXIGrRtDfDVaA)]
- Learning to Transduce with Unbounded Memory. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjYu-D0hNPQAhUMNrwKHew8AsYQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.02516&usg=AFQjCNEeCL4SV0s8JCtxAARLeLz7S1kC0A)]
- Listen, Attend and Spell. [[pdf]](docs/2015/Listen, Attend and Spell.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjW4bqThdPQAhULf7wKHWS4Cl0QFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1508.01211&usg=AFQjCNEmyppRaNABjzOP4soC2IQd8M8hNw)]
- <b>LSTM A Search Space Odyssey</b>. [[pdf]](docs/2015/LSTM A Search Space Odyssey(2015).pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiigPSrhdPQAhWJW7wKHSH7D8IQFggrMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1503.04069&usg=AFQjCNEpZAcQ8c5a6GMsBWBAy-pbcbjS2g)]
- LSTM-based Deep Learning Models for non-factoid answer selection. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj-rpDLhdPQAhXJErwKHaPAAyoQFggtMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.04108&usg=AFQjCNEKrHqjvUSmXuI9zBwPBcMDDUOe5w)]
- Net2Net-Accelerating Learning via Knowledge Transfer. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiburbphtPQAhVCVbwKHVOuAcsQFgggMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.05641&usg=AFQjCNHYQzsRziUVIU8SAhq2H_XuLuiLcw)]
- Neural GPUs Learn Algorithms. [[pdf]](docs/2015/Neural GPUs Learn Algorithms.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjKoce8ndPQAhVFx7wKHdIZCtYQFggdMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.08228&usg=AFQjCNFSo5DutEjXcPPeHJOS2ZLhVSLKog)]
- Neural Programmer- Inducing Latent Programs with Gradient Descent. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjQg9nUndPQAhVDwLwKHbmaCskQFggsMAE&url=https%3A%2F%2Fpeople.cs.umass.edu%2F~arvind%2Fnp.pdf&usg=AFQjCNEpIyC6zWXQT44MmmZStNjMUSbHcw)]
- <b>Pointer Networks</b>. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjO2afkntPQAhXGw7wKHdjSAJIQFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.03134&usg=AFQjCNHyhe83B6QkuFCeActJjUHaiMB4Pg)]
- Poker-CNN- A Pattern Learning Strategy for Making Draws and Bets in Poker Games. [[pdf]](docs/2015/Poker-CNN- A Pattern Learning Strategy for Making Draws and Bets in Poker Games.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjZrJeXn9PQAhUByrwKHV2pBQEQFggrMAE&url=http%3A%2F%2Fcolinraffel.com%2Fpublications%2Faaai2016poker.pdf&usg=AFQjCNGpLMFh8m91SLrHvu7vBbCGy3CW_g)]
- Policy distillation. [[arxiv](https://arxiv.org/abs/1511.06295)]
- Regularizing RNNs by Stabilizing Activations. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjX9YWBoNPQAhUSNrwKHfg8AuwQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.08400&usg=AFQjCNGxE7PHSagmWUBIAw4zRLZx5fDxZQ)]
- ReNet- A Recurrent Neural Network Based Alternative to Convolutional Networks. [[pdf]](docs/2015/ReNet- A Recurrent Neural Network Based Alternative to Convolutional Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjextOooNPQAhWKUbwKHecwDmgQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1505.00393&usg=AFQjCNEJLTApjlKqYKQIizZLr3nS1Sy-fA)]
- ReSeg- A Recurrent Neural Network for Object Segmentation. [[pdf]](docs/2015/ReSeg- A Recurrent Neural Network for Object Segmentation.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj1-sbBoNPQAhXCfrwKHZH8DnQQFggnMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.07053&usg=AFQjCNF8WsGCR2nS5XYAShF_zzTfvd1ckg)]
- <b>Rethinking the Inception Architecture for Computer Vision</b>. [[pdf]](docs/2015/Rethinking the Inception Architecture for Computer Vision.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiRnMzcoNPQAhUENbwKHSxSATAQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1512.00567&usg=AFQjCNH8cDaqKtWdPI89vZv9MFeHTjlR4w)]
- <b>Semi-Supervised Learning with Ladder Networks</b>. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiPmrj4oNPQAhWJVbwKHbpjAB0QFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1507.02672&usg=AFQjCNHN95nVk-ZgIVniY-5O8P8niql8Pg)]
- Session-based Recommendations with Recurrent Neural Networks. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi2uPD7odPQAhVIfrwKHYjqAJsQFggjMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.06939&usg=AFQjCNHQCiJnwlyuU39SYkgDhP9lAckyIg)]
- <b>Skip-Thought Vectors</b>. [[pdf]](docs/2015/Skip-Thought Vectors.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiv7tXaotPQAhVKfrwKHUkID6wQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.06726&usg=AFQjCNGgfIfg5leG9gyRlO0EUjl-c-rYVQ)]
- [Spatial Transformer Networks.](http://blog.csdn.net/shaoxiaohu1/article/details/51809605) [[pdf]](docs/2015/Spatial Transformer Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiEgJz0otPQAhXHmZQKHXM3DJUQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.02025&usg=AFQjCNH5DcVI1dz_3sTqdgvi3rmITcGN7g)]
- <b>Training Very Deep Networks.</b> [[pdf]](docs/2015/Training Very Deep Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiMvvHuo9PQAhXDxbwKHZjSCtgQFggiMAA&url=http%3A%2F%2Farxiv.org%2Fabs%2F1507.06228&usg=AFQjCNHkQ_NfRPI9BQgrHI_wn2zFgOtrSA)]
- Tree-structured composition in neural networks without tree-structured architectures. [[pdf]](docs/2015/Tree-structured composition in neural networks without tree-structured architectures.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjl5e6MpNPQAhVGNrwKHdozBbwQFggtMAE&url=http%3A%2F%2Fceur-ws.org%2FVol-1583%2FCoCoNIPS_2015_paper_5.pdf&usg=AFQjCNFpO43q61p6ROBIFOx94CPr9EAdLQ)]

### Natural language process

- A Primer on Neural Network Models for Natural Language Processing. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjr-I3b-9LQAhVEVbwKHVo8A70QFggsMAE&url=http%3A%2F%2Fcs.biu.ac.il%2F~yogo%2Fnnlp.pdf&usg=AFQjCNEZEkggUYseGdLhpFy_iG5mBA3X9g)]
- A Unified Tagging Solution- Bidirectional LSTM Recurrent Neural Network with Word Embedding.  [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj-t_LG_NLQAhVES7wKHWTtCmIQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.00215&usg=AFQjCNECqO7dKUb1L7bkvFFR_8-hgPy52w)]
- Alternative structures for character-level RNNs. [[pdf]](docs/2015/Alternative structures for character-level RNNs.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiyx_iZ_dLQAhUBT7wKHUE0A38QFggqMAE&url=http%3A%2F%2Fwww.di.ens.fr%2F~bojanowski%2Fpapers%2Fbojanowski16alternative.pdf&usg=AFQjCNF0ds1vVOijyqtBX-g_s9x8OedIbg)]
- Ask Me Anything- Dynamic Memory Networks for Natural Language Processing. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiH8Kjf_dLQAhXIxLwKHU7QAb8QFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.07285&usg=AFQjCNFjdb3GPe1IrNPSh8zevJazf58JwQ)]
- BlackOut- Speeding up Recurrent Neural Network Language Models With Very Large Vocabularies. [[url](https://arxiv.org/abs/1511.06909)]
- <b>Character-Aware Neural Language Models.</b> [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjJ7JjA_9LQAhVDwLwKHbmaCskQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1508.06615&usg=AFQjCNG3RqYNgZfsn7zIez3SEzwB70cEKg)]
- Character-level Convolutional Networks for Text Classification. [[pdf]](docs/2015/Character-level Convolutional Networks for Text Classification.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiE5qTl_9LQAhUEWLwKHcHaDQgQFggsMAE&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5782-character-level-convolutional-networks-for-text-classification.pdf&usg=AFQjCNFInMceTBvIU8_8XmtKfoizKGpOVA)]
- <b>Deep Speech 2- End-to-End Speech Recognition in English and Mandarin.</b> [[pdf]](docs/2015/Deep Speech 2- End-to-End Speech Recognition in English and Mandarin.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwi5uvCDgdPQAhVFwLwKHSJ6B0MQFggvMAE&url=http%3A%2F%2Fjmlr.org%2Fproceedings%2Fpapers%2Fv48%2Famodei16.pdf&usg=AFQjCNFE5u2Xu81DH2gQUoyHVtC4AzLhYg)]
- <b>Distributed Representations of Sentences and Documents</b>. [[pdf]](docs/2015/Distributed Representations of Sentences and Documents.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjf2ZyrgtPQAhWJvrwKHTV4BqsQFgguMAE&url=http%3A%2F%2Fcs.stanford.edu%2F~quocle%2Fparagraph_vector.pdf&usg=AFQjCNESECVF_9eXAkAjfSqqHrqlxkVQgg)]
- Dynamic Capacity Networks. [[pdf]](docs/2015/Dynamic Capacity Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiN_Yj0gtPQAhVPQLwKHVz0BZwQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.07838&usg=AFQjCNFR0AEK2z-pT8ulDl98QWXP0M3fCw)]
- Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs. [[pdf]](docs/2015/Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjy35b6g9PQAhUDx7wKHULuChcQFggsMAE&url=https%3A%2F%2Fwww.aclweb.org%2Fanthology%2FD%2FD15%2FD15-1041.pdf&usg=AFQjCNHhOsMGNAY4FXq5-B9dDjy-OPBWvA)]
- Larger-Context Language Modeling. [[pdf]](docs/2015/Larger-Context Language Modeling.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjHlvWshNPQAhWLybwKHTiuB-0QFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1511.03729&usg=AFQjCNG88NnFeKSPKis1dVnVNYa0Tu50Gw)]
- Multi-task Sequence to Sequence Learning. [[pdf]](docs/2015/Multi-task Sequence to Sequence Learning.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiu7MbphdPQAhWDUrwKHeo3DO8QFggpMAE&url=http%3A%2F%2Fjan.stanford.edu%2Fpubs%2Fluong2016iclr_multi.pdf&usg=AFQjCNGYWAqWnjbi6p3ZXWe0hBcNMSWawA)]
- Natural Language Understanding with Distributed Representation. [[pdf]](docs/2015/Natural Language Understanding with Distributed Representation.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjhm4yThtPQAhWJVrwKHY-fDusQFggiMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.07916&usg=AFQjCNEXqHl1eNACFv-e99vq-omz4TcY_Q)]
- Neural Machine Translation of Rare Words with Subword Units. [[arxiv](https://arxiv.org/abs/1508.07909)]
- Neural Responding Machine for Short-Text Conversation. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiT-aOMntPQAhXHwbwKHXcqAzYQFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1503.02364&usg=AFQjCNETeT0aqPYSdo-fP-DYyl7WZg2BqQ)]
- Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Recurrent Neural Network. [[pdf]](docs/2015/Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Recurrent Neural Network.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwigxZnPntPQAhUCybwKHRJrCc8QFggiMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1510.06168&usg=AFQjCNEIDEbarhumVAtwYDPin-r5-10mSQ)]
- Reading Scene Text in Deep Convolutional Sequences. [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjnwcaJpY7RAhVnwlQKHdQhBMkQFggrMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.04395&usg=AFQjCNFwWEe1FlLYwTvy5JrYCme9M_QREA)]
- Recurrent Convolutional Neural Networks for Text Classification. [[pdf](https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=0ahUKEwip1u_yqpTRAhXGz1QKHUGDCc8QFggxMAI&url=http%3A%2F%2Fwww.aaai.org%2Focs%2Findex.php%2FAAAI%2FAAAI15%2Fpaper%2Fdownload%2F9745%2F9552&usg=AFQjCNFn9tI5wMb1f81hDQPHySE9C2OOpA)]
- Semi-supervised Sequence Learning. [[pdf]](docs/2015/Semi-supervised Sequence Learning.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwj28pOnodPQAhUJT7wKHb_eDpIQFggiMAA&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5949-semi-supervised-sequence-learning.pdf&usg=AFQjCNFi_8bOPu361mtaI13MWB_aHDlspg)]
- Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems. [[arxiv](https://arxiv.org/abs/1508.01745)]
- sense2vec - A Fast and Accurate Method for Word Sense Disambiguation In Neural Word Embeddings. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=4&cad=rja&uact=8&ved=0ahUKEwiQ_aHDodPQAhUITLwKHYP2B2kQFgg5MAM&url=https%3A%2F%2Fpdfs.semanticscholar.org%2F36f9%2F886ad1cb9ee3f66c5af0282ae7a3359b86b2.pdf&usg=AFQjCNE7oWW1uaAuK2skjRUnPXhykGFeMw)]
- Sequence Level Training with Recurrent Neural Networks. [[pdf]](docs/2015/Sequence Level Training with Recurrent Neural Networks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjEgIbnodPQAhUKyrwKHXJICVUQFgghMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1511.06732&usg=AFQjCNGEymvqFAIJnyEUAh0Ok7dImTDJjg)]
- Strategies for Training Large Vocabulary Neural Language Models. [[pdf]](docs/2015/Strategies for Training Large Vocabulary Neural Language Models.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjE1KCTo9PQAhXHwrwKHeTfDZ8QFggsMAE&url=http%3A%2F%2Fwww.aclweb.org%2Fanthology%2FP%2FP16%2FP16-1186.pdf&usg=AFQjCNGUJ0zFy2G4j9x9enwYuu2iTN5cig)]
- Teaching Machines to Read and Comprehend. [[pdf]](docs/2015/Teaching Machines to Read and Comprehend.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiu6Y2no9PQAhUJS7wKHYB-BjwQFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1506.03340&usg=AFQjCNEhq-W8rar0b08n_Vt3CSkeOFTJLw)]
- Towards Universal Paraphrastic Sentence Embeddings. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjM-u3Jo9PQAhUDbrwKHXETBuAQFggtMAE&url=http%3A%2F%2Fttic.uchicago.edu%2F~wieting%2Fwieting2016ICLR.pdf&usg=AFQjCNFMW6NpxCP9FMXpati4GbmkkCgPWQ)]
- Visualizing and Understanding Neural Models in NLP. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=0ahUKEwjszoDFpNPQAhWIxbwKHYlEAV0QFgg2MAI&url=https%3A%2F%2Fweb.stanford.edu%2F~jurafsky%2Fpubs%2Fvisualizing16.pdf&usg=AFQjCNECNXN2Cf42XcZokv2o5sE6RNM41Q)]

### Adversarial network

- Autoencoding beyond pixels using a learned similarity metric. [[arxiv](https://arxiv.org/abs/1512.09300)]
- [LAPGAN] Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks. [[arxiv](https://arxiv.org/abs/1506.05751)] [[code](https://github.com/facebook/eyescream)]
- Generative Image Modeling Using Spatial LSTMs. [[arxiv](https://arxiv.org/abs/1506.03478)]
- Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks. [[arxiv](https://arxiv.org/abs/1511.06390)]
- [DCGAN] <b>Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</b>. [[pdf]](docs/2015/Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.pdf) [[arxiv](https://arxiv.org/abs/1511.06434)] [[code](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjjzcaIpqDRAhVKw1QKHZ6eDxEQFggrMAE&url=https%3A%2F%2Fgithub.com%2FNewmu%2Fdcgan_code&usg=AFQjCNFLjTPZgeru6CC8JHyS327QIW7EEg)]

### Attention and memory

- Attention with Intention for a Neural Network Conversation Model. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj--cv5_dLQAhUJv7wKHenpD3EQFggpMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1510.08565&usg=AFQjCNHP09eh3A7Ys6D6bqDbhyb9SAuixQ)]
- <b>End-To-End Memory Networks.</b> [[arxiv](https://arxiv.org/abs/1503.08895)]
- <b>Show, Attend and Tell- Neural Image Caption Generation with Visual Attention</b>. [[pdf]](docs/2015/Show, Attend and Tell- Neural Image Caption Generation with Visual Attention.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiwwZmqotPQAhWCvbwKHZFwD9IQFggwMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1502.03044&usg=AFQjCNECNcNjKjJkda1TxlcPtNO4dbTiEw)]
- Agreement-based Joint Training for Bidirectional Attention-based Neural Machine Translation. [[arxiv](https://arxiv.org/abs/1512.04650)] 
- Ask Me Anything: Dynamic Memory Networks for Natural Language Processing. [[arxiv](https://arxiv.org/abs/1506.07285)]
- <b>A Neural Attention Model for Sentence Summarization</b>. [[pdf](docs/2015/A Neural Attention Model for Sentence Summarization.pdf)] [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiJnNOM-9LQAhVGWrwKHTH3BFAQFggiMAA&url=https%3A%2F%2Fwww.aclweb.org%2Fanthology%2FD%2FD15%2FD15-1044.pdf&usg=AFQjCNFw54b4APRJXCmpk2Yf0ttsATDZNA)]
- [VAE with attention] DRAW: A Recurrent Neural Network For Image Generation. [[arxiv](https://arxiv.org/abs/1502.04623)] [[code](https://github.com/ericjang/draw)]
- <b>Effective Approaches to Attention-based Neural Machine Translation</b>. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjhkfGlotjQAhXFULwKHTzhA1YQFggmMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1508.04025&usg=AFQjCNHOjFZaEvp3YSwQTEhrgmmLW6ER8g)]
- End-to-End Attention-based Large Vocabulary Speech Recognition. [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwi7y9Dbvo7RAhVF0FQKHa3SCAoQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1508.04395&usg=AFQjCNE-iJp1IdJm552na5qzcFJNQ85cxA)]

### Transfer learning

- Transfer Learning from Deep Features for Remote Sensing and Poverty Mapping. [[arxiv](https://arxiv.org/abs/1510.00098)]
- Transfer learning using computational intelligence: A survey. [[url](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiy2_T1tY7RAhXBwFQKHXTrAUEQFggqMAE&url=https%3A%2F%2Fpdfs.semanticscholar.org%2F21bb%2Fec954226c5fdf53560cb072188a18051683c.pdf&usg=AFQjCNHTlj0iUN_xNVabR1ZRsyiEgkJmFg)]

### Deep reinforcement learning

- ADAAPT: A Deep Architecture for Adaptive Policy Transfer from Multiple Sources, J. Rajendran et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1510.02879)]
- <b>Action-Conditional Video Prediction using Deep Networks in Atari Games</b>, J. Oh et al., *NIPS*.  [[arxiv](http://arxiv.org/abs/1507.08750)]
- Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning. [[arxiv](https://arxiv.org/abs/1511.06342)]
- [DDPG] Continuous control with deep reinforcement learning. [[arxiv](https://arxiv.org/abs/1509.02971)]
- [NAF] Continuous Deep Q-Learning with Model-based Acceleration. [[arxiv](https://arxiv.org/abs/1603.00748)]
- <b>Dueling Network Architectures for Deep Reinforcement Learning</b>, Z. Wang et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1511.06581)]
- Deep Reinforcement Learning with an Action Space Defined by Natural Language, J. He et al., *arXiv*. [[arxiv](http://arxiv.org/abs/1511.04636)]
- <b>Deep Reinforcement Learning with Double Q-learning</b>, H. van Hasselt et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1509.06461)]
- <b>Deep Recurrent Q-Learning for Partially Observable MDPs</b>, M. Hausknecht and P. Stone, *arXiv*.  [[arxiv](http://arxiv.org/abs/1507.06527)]
- DeepMPC: Learning Deep Latent Features for Model Predictive Control, I. Lenz, et al., *RSS*.  [[url](http://deepmpc.cs.cornell.edu/DeepMPC.pdf)]
- <b>Deterministic Policy Gradient Algorithms</b>, D. Silver et al., *ICML*.  [[url](http://jmlr.org/proceedings/papers/v32/silver14.pdf)]
- Dueling Network Architectures for Deep Reinforcement Learning. [[arxiv](https://arxiv.org/abs/1511.06581)]
- <b>End-to-End Training of Deep Visuomotor Policies</b>, S. Levine et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1504.00702)]
- Giraffe: Using Deep Reinforcement Learning to Play Chess, M. Lai, *arXiv*.  [[arxiv](http://arxiv.org/abs/1509.01549)]
- Generating Text with Deep Reinforcement Learning, H. Guo, *arXiv*.  [[arxiv](http://arxiv.org/abs/1510.09202)]
- How to Discount Deep Reinforcement Learning: Towards New Dynamic Strategies, V. François-Lavet et al., *NIPS Workshop*.  [[arxiv](http://arxiv.org/abs/1512.02011)]
- <b>Human-level control through deep reinforcement learning</b>, V. Mnih et al., *Nature*.  [[url](http://www.nature.com/nature/journal/v518/n7540/pdf/nature14236.pdf)]
- <b>Incentivizing Exploration In Reinforcement Learning With Deep Predictive Models</b>, B. C. Stadie et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1507.00814)]
- Learning Simple Algorithms from Examples, W. Zaremba et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1511.07275)]
- <b>Language Understanding for Text-based Games Using Deep Reinforcement Learning</b>, K. Narasimhan et al., *EMNLP*.  [[url](http://people.csail.mit.edu/karthikn/pdfs/mud-play15.pdf)]
- <b>Learning Continuous Control Policies by Stochastic Value Gradients</b>, N. Heess et al., *NIPS*.  [[url](http://papers.nips.cc/paper/5796-learning-continuous-control-policies-by-stochastic-value-gradients.pdf)]
- Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences, H. Mei et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1506.04089)]
- Learning Deep Neural Network Policies with Continuous Memory States, M. Zhang et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1507.01273)]
- Multiagent Cooperation and Competition with Deep Reinforcement Learning, A. Tampuu et al., *arXiv*.  [[arxiv](http://arxiv.org/abs/1511.08779)]
- Maximum Entropy Deep Inverse Reinforcement Learning, M. Wulfmeier et al., *arXiv*. [[arxiv](http://arxiv.org/abs/1507.04888)]
- <b>Massively Parallel Methods for Deep Reinforcement Learning</b>, A. Nair et al., *ICML Workshop*.  [[url](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Publications_files/gorila.pdf)]
- Memory-based control with recurrent neural networks, N. Heess et al., *NIPS Workshop*.  [[arxiv](http://arxiv.org/abs/1512.04455)]
- On Learning to Think- Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models.  [[arxiv](https://arxiv.org/pdf/1511.09249)]
- Playing Atari with Deep Reinforcement Learning. [[arxiv](https://arxiv.org/abs/1312.5602)]
- Recurrent Reinforcement Learning: A Hybrid Approach, X. Li et al., *arXiv*. [[arxiv](http://arxiv.org/abs/1509.03044)]
- Reinforcement Learning Neural Turing Machines. [[arxiv](https://arxiv.org/abs/1505.00521)]
- Strategic Dialogue Management via Deep Reinforcement Learning, H. Cuayáhuitl et al., *NIPS Workshop*. [[arxiv](http://arxiv.org/abs/1511.08099)]
- Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control, F. Zhang et al., *arXiv*. [[arxiv](http://arxiv.org/abs/1511.03791)]
- <b>Trust Region Policy Optimization</b>, J. Schulman et al., *ICML*. [[url](http://jmlr.org/proceedings/papers/v37/schulman15.pdf)]
- Universal Value Function Approximators, T. Schaul et al., *ICML*. [[url](http://schaul.site44.com/publications/uvfa.pdf)]
- Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning, S. Mohamed and D. J. Rezende, *arXiv*. [[arxiv](http://arxiv.org/abs/1509.08731)]