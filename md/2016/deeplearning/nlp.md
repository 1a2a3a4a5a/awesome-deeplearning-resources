## natural language process

- <b>A Character-level Decoder without Explicit Segmentation for Neural Machine Translation</b>. [[pdf]](docs/2016/A Character-level Decoder without Explicit Segmentation for Neural Machine Translation.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiZr6_ZpdPQAhWEu7wKHT_1AJ4QFggpMAE&url=https%3A%2F%2Fwww.aclweb.org%2Fanthology%2FP%2FP16%2FP16-1160.pdf&usg=AFQjCNGNp_ng6FPcHatCYdgRC_jIsiufkg)]
- A Joint Many-Task Model- Growing a Neural Network for Multiple NLP Tasks. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiOjsTEp9PQAhWIwrwKHVeJBcsQFgggMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1611.01587&usg=AFQjCNHqixpFo9T8V4ayxskWgKMHkMtTCw)]
- A Semisupervised Approach for Language Identification based on Ladder Networks. [[pdf](docs/2016/A Semisupervised Approach for Language Identification based on Ladder Networks.pdf)] [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=0ahUKEwiSmPz52dXQAhUJbbwKHb4BA48QFgguMAI&url=http%3A%2F%2Fwww.eng.biu.ac.il%2Fgoldbej%2Ffiles%2F2012%2F05%2FOdyssey_2016_paper.pdf&usg=AFQjCNGvxKufUzYjNCPDczZkWZ21H4sT-g)]
- Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiwufX42tXQAhWCVbwKHZrPBOUQFgguMAE&url=https%3A%2F%2Faclweb.org%2Fanthology%2FK%2FK16%2FK16-1028.pdf&usg=AFQjCNHuJk3k7At-iCnwPJIQEE9GzvOFZg)]
- <b>Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</b>. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj_6-WU3NXQAhWLa7wKHRpZD3oQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1604.00788&usg=AFQjCNHOLFSPTHsYZYKfnpklteKsVEwScQ)]
- Aspect Level Sentiment Classification with Deep Memory Network. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwja0LeI3tXQAhXMgLwKHZ83A04QFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1605.08900&usg=AFQjCNGfnoyCcCzGnIDOhLeYky4UdUa2OQ)]
- <b>Character-based Neural Machine Translation.</b> [[url](https://arxiv.org/abs/1511.04586)]
- COCO-Text-Dataset and Benchmark for Text Detection and Recognition in Natural Images. [[pdf]](docs/2016/COCO-Text- Dataset and Benchmark for Text Detection and Recognition in Natural Images.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=0ahUKEwjWwraRgdjQAhVFwLwKHUhQCCQQFggxMAI&url=http%3A%2F%2Fsunw.csail.mit.edu%2Fpapers%2F01_Veit_SUNw.pdf&usg=AFQjCNEd0KdDVoHqEmAv4JVphvSIaTG_eg)]
- Context-Dependent Word Representation for Neural Machine Translation. [[url](https://arxiv.org/pdf/1607.00578.pdf)]
- <b>Contextual LSTM (CLSTM) models for Large scale NLP tasks</b>.[[pdf]](docs/2016/Contextual LSTM (CLSTM) models for Large scale NLP tasks.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiQ8O-YgtjQAhXGvrwKHV4OAA4QFggqMAE&url=http%3A%2F%2Fwww.csl.sri.com%2Fusers%2Fshalini%2Fclstm_dlkdd16.pdf&usg=AFQjCNFDWWi_vCjbubOD_XcN-IuQ6uotTQ)]
- Convolutional Encoders for Neural Machine Translation. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiRztLsgtjQAhUJybwKHYZNBI8QFggfMAA&url=https%3A%2F%2Fcs224d.stanford.edu%2Freports%2FLambAndrew.pdf&usg=AFQjCNGc36jpBqQdaKI19b67nIEnkaZmxw)]
- Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translatin. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjs08KahtjQAhVNQLwKHV8_DC0QFggmMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1606.04199&usg=AFQjCNGE9o3aCzRNtLcwaKfUjO7FV2gYaA)]
- Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models. [[url](https://arxiv.org/abs/1610.02424)]
- Dual Learning for Machine Translation. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjpoa3dhtjQAhWJTLwKHWr0DqYQFggrMAE&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F6469-dual-learning-for-machine-translation.pdf&usg=AFQjCNHMsJHcP9wBymQ7yFPMn8P_34nzfA)]
- Efficient Character-level Document Classification by Combining Convolution and Recurrent Layers. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwj1yYXdh9jQAhXCebwKHW8vDMMQFggeMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1602.00367&usg=AFQjCNF15R9nAUvB5OqWHM2bwLwgrxRPBw)]
- <b>End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</b>. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjaiLCOiNjQAhWMv7wKHeLQCfsQFggeMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1603.01354&usg=AFQjCNG-KfCDJTOPEYjMoohV-fdTGOK9ew)]
- Fully Character-Level Neural Machine Translation without Explicit Segmentation. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=0ahUKEwjzm5bji9jQAhWKXbwKHY7XDq4QFggyMAI&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1610.03017&usg=AFQjCNHnbc8-GslAad2RBzmrV2ppgRsbmQ)]
- Gated-Attention Readers for Text Comprehension. [[pdf]](docs/2016/Gated-Attention Readers for Text Comprehension.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwi03LiIjNjQAhUFO7wKHXUmAE4QFggnMAE&url=https%3A%2F%2Fopenreview.net%2Fpdf%3Fid%3DHkcdHtqlx&usg=AFQjCNF8nqsWtlgBgepZz-U1diL7mcGaYg)]
- <b>Generating Factoid Questions With Recurrent Neural Networks- The 30M Factoid Question-Answer Corpus</b>. [[pdf]](docs/2016/Generating Factoid Questions With Recurrent Neural Networks- The 30M Factoid Question-Answer Corpus.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjupJy3jNjQAhUCQLwKHTE5AVEQFggnMAE&url=https%3A%2F%2Faclweb.org%2Fanthology%2FP%2FP16%2FP16-1056.pdf&usg=AFQjCNGmLcxTx3Kq2u_yktAPC2XVzpmLzw)]
- Google's Multilingual Neural Machine Translation System- Enabling Zero-Shot Translation. [[pdf]](docs/2016/Google's Multilingual Neural Machine Translation System- Enabling Zero-Shot Translation.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiwnYPSjdjQAhXMvLwKHfAdCwkQFggjMAE&url=https%3A%2F%2Farxiv.org%2Fabs%2F1611.04558&usg=AFQjCNEOkgAI_1Cj_4LoU6pZjGj9s9VdMA)]
- <b>Google's Neural Machine Translation System- Bridging the Gap between Human and Machine Translation</b>. [[pdf]](docs/2016/Google's Neural Machine Translation System- Bridging the Gap between Human and Machine Translation.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwio0qP2jdjQAhUHvrwKHXuxCiIQFgghMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1609.08144&usg=AFQjCNHrQteiCIO8woQ1piRonQeZbYaYtw)]
- <b>Hierarchical Attention Networks for Document Classification</b>. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiF7N7ej9jQAhWIu7wKHVmKB6MQFgggMAA&url=https%3A%2F%2Fwww.cs.cmu.edu%2F~diyiy%2Fdocs%2Fnaacl16.pdf&usg=AFQjCNFokKFJ1g7WQSDYkYEM82XwhGiDGw)]
- How Grammatical is Character-level Neural Machine Translation? Assessing MT Quality with Contrastive Translation Pairs.[[url](https://arxiv.org/abs/1612.04629)]
- Iterative Alternating Neural Attention for Machine Reading. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjt79qFktjQAhVIvrwKHe5cCGgQFggrMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1606.02245&usg=AFQjCNF3I_gZskJ890hJzpm2_3yIUVeEsg)]
- Key-Value Memory Networks for Directly Reading Documents. [[pdf]](docs/2016/Key-Value Memory Networks for Directly Reading Documents.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjT98WjktjQAhVDOrwKHfi7CbgQFggmMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1606.03126&usg=AFQjCNEWuqc4X4BJjsozF8U7cxT9RgJXLA)]
- <b>Language to Logical Form with Neural Attention.</b> [[pdf]](docs/2016/Language to Logical Form with Neural Attention.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=0ahUKEwjlhojaldjQAhVGfLwKHYfZAaEQFggvMAI&url=http%3A%2F%2Fhomepages.inf.ed.ac.uk%2Fs1478528%2Facl16-lang2logic-slides.pdf&usg=AFQjCNFfAVG7Xp0RYOo1H4AplPhTvKCayQ)]
- <b>Learning Distributed Representations of Sentences from Unlabelled Data</b>. [[pdf]](docs/2016/Learning Distributed Representations of Sentences from Unlabelled Data.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiNu9WMl9jQAhUEi7wKHVSaBsoQFggmMAE&url=https%3A%2F%2Farxiv.org%2Fabs%2F1602.03483&usg=AFQjCNFOfq3lrKNBm8yW1nypxMPW8FpZxQ)]
- <b>Learning to Compose Neural Networks for Question Answering.</b> [[pdf]](docs/2016/Learning to Compose Neural Networks for Question Answering.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwj_8fHcl9jQAhWCvLwKHcn7DwQQFggeMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1601.01705&usg=AFQjCNGpVsvadnfc-k6tUlbaFXZWCQwzcg)]
- Learning to Translate in Real-time with Neural Machine Translation. [[pdf]](docs/2016/Learning to Translate in Real-time with Neural Machine Translation.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjLy53pmNjQAhVDS7wKHbj3CzcQFggeMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1610.00388&usg=AFQjCNGgqFSIWXA5ZAO5of1_Opvd1W9OoQ)]
- <b>Long Short-Term Memory-Networks for Machine Reading.</b> [[pdf]](docs/2016/Long Short-Term Memory-Networks for Machine Reading.pdf) [[url](https://aclweb.org/anthology/D16-1053)]
- Memory-enhanced Decoder for Neural Machine Translation. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjo_ezwntjQAhUBvbwKHdrrBzkQFggfMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1606.02003&usg=AFQjCNFi6ZffMp9CIjAr3oWHtfZCP5YpCg)]
- <b>Modeling Coverage for Neural Machine Translation.</b> [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=0ahUKEwin36mKn9jQAhWIV7wKHeQsDwoQFgg4MAI&url=http%3A%2F%2Fwww.hangli-hl.com%2Fuploads%2F3%2F4%2F4%2F6%2F34465961%2Ftu_et_al_2016.pdf&usg=AFQjCNEUvqmUoV_80qehwowDJxiTKPb56g)]
- <b>Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism</b>. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwibwPzrn9jQAhWEWLwKHYjDAOwQFggnMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1601.01073&usg=AFQjCNGBCM_nN20wGuG4LsZX_0F5CBfLvQ)]
- <b>Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss.</b> [[pdf]](docs/2016/Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss.pdf) [[url](https://www.aclweb.org/anthology/P/P16/P16-2067.pdf)]
- Neural Architectures for Fine-grained Entity Type Classification. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi49K6xodjQAhWKu7wKHVH8C3UQFggeMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1606.01341&usg=AFQjCNEBbHYxkxaY1brRzVM-dwjCgxq4RQ)]
- <b>Neural Architectures for Named Entity Recognition.</b> [[pdf]](docs/2016/Neural Architectures for Named Entity Recognition.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi7rMfIodjQAhXCv7wKHXQ-CqQQFgggMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1603.01360&usg=AFQjCNEz4-0yI6uDqSCGnCQoDS3FdENHKQ)]
- Neural Language Correction with Character-Based Attention.  [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjBmYDwodjQAhXMTLwKHb_HB5sQFggeMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1603.09727&usg=AFQjCNHJRTjauP0qBRF20-J6Qpzq1Odxdw)]
- Neural Machine Translation in Linear Time. [[pdf]](docs/2016/Neural Machine Translation in Linear Time.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjn5tGIotjQAhWKiLwKHUfSDtsQFggiMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1610.10099&usg=AFQjCNHrnVpbFg6yFqb238lgScLZOEcISw)]
- Neural Machine Translation with Recurrent Attention Modeling. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjhkfGlotjQAhXFULwKHTzhA1YQFggbMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1607.05108&usg=AFQjCNFLr_lvHbiSPwL3pP5mq0EHdGZiDA)]
- Neural Network Translation Models for Grammatical Error Correction. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi4pcSMo9jQAhULT7wKHZmlBlQQFggvMAA&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1606.00189&usg=AFQjCNH4q8_JVt6qRe-Gmlwlr1dz-ugqtA)]
- Neural Semantic Encoders. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjHnrnYo9jQAhVH2LwKHXD9AF0QFggbMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1607.04315&usg=AFQjCNFuWivmRnejx165YchYZ6wMsB-snA)]
- <b>Neural Variational Inference for Text Processing</b>. [[url](https://arxiv.org/pdf/1511.06038)]
- On Random Weights for Texture Generation in One Layer Neural Networks.[[url](https://arxiv.org/abs/1612.06070?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%253A+arxiv%252FQSXk+%2528ExcitingAds%2521+cs+updates+on+arXiv.org%2529)]
- Parallelizing Word2Vec in Shared and Distributed Memory.[[url](https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwislK6JnYnRAhUT0mMKHZq5CisQFggoMAE&url=%68%74%74%70%73%3a%2f%2f%70%64%66%73%2e%73%65%6d%61%6e%74%69%63%73%63%68%6f%6c%61%72%2e%6f%72%67%2f%63%63%65%64%2f%63%33%38%66%36%38%66%66%61%66%35%31%63%66%38%63%33%31%63%64%36%63%36%62%35%63%32%63%66%30%33%33%66%39%31%61%2e%70%64%66&usg=AFQjCNEKxUsONrbDHc1Zn1smfAWc4wpSlg)] [[github](https://github.com/IntelLabs/pWord2Vec)]
- Recurrent Memory Networks for Language Modeling. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiM-uaop9jQAhWEjLwKHacvB_oQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1601.01272&usg=AFQjCNE1W-90ZYxVaCls2sBch5JuzPbVcA)]
- Recurrent Neural Machine Translation. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjbzcDKp9jQAhVMzLwKHZ2FDqIQFggbMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1607.08725&usg=AFQjCNEl13PMYPOwO2mTcCK_bdwUNFTdNQ)]
- <b>Recurrent Neural Network Grammars.</b> [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiu9uDep9jQAhXEerwKHU3QC_kQFgggMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1602.07776&usg=AFQjCNEy_Q-Yep2tn5g00XWwjiGcNgOnrg)]
- Sentence Level Recurrent Topic Model- Letting Topics Speak for Themselves. [[pdf]](docs/2016/Sentence Level Recurrent Topic Model- Letting Topics Speak for Themselves.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiEnpWvqtjQAhWEVrwKHYS3B0YQFggeMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1604.02038&usg=AFQjCNGkbzfhZME1hdwVrys_l_9pg-L-hA)]
- Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction. [[pdf]](docs/2016/Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj87-7nqtjQAhUBtZQKHdJiCuUQFggqMAE&url=https%3A%2F%2Faclweb.org%2Fanthology%2FW%2FW16%2FW16-0528.pdf&usg=AFQjCNFB0nh4eIORsJTs4MJ5NdHPCnFaqw)]
- SeqGAN- Sequence Generative Adversarial Nets with Policy Gradient. [[pdf]](docs/2016/SeqGAN- Sequence Generative Adversarial Nets with Policy Gradient.pdf) [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjY0NWEq9jQAhXEEbwKHReIDrQQFggeMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1609.05473&usg=AFQjCNHxaAv6rC-G4DbBpCkEvcgEdKGWeQ)]
- Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation. [[url](https://arxiv.org/abs/1607.00970)]
- Temporal Attention Model for Neural Machine Translation. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiQipLur9jQAhXMS7wKHU2dC6IQFgggMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1608.02927&usg=AFQjCNFbmrm7D9W3GN1Luapp-sRVHqKlKA)]
- Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors. [[url](https://arxiv.org/abs/1612.03969)]
- Unsupervised Pretraining for Sequence to Sequence Learning. [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwidp53EsdjQAhVMzbwKHeSfBa4QFggjMAA&url=https%3A%2F%2Farxiv.org%2Fabs%2F1611.02683&usg=AFQjCNHdHMJUM2OIgLMaZs5wpbXfXvN4gA)]
- Very Deep Convolutional Networks for Natural Language Processing. [[pdf](docs/2016/Very Deep Convolutional Networks for Natural Language Processing.pdf)] [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwjj79_ZsdjQAhVJy7wKHRLdAJEQFggsMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1606.01781&usg=AFQjCNEX8WGvkSXZgPzlKLelkfkhlC2Tnw)]
- Zero-Resource Translation with Multi-Lingual Neural Machine Translation. [[pdf](docs/2016/Zero-Resource Translation with Multi-Lingual Neural Machine Translation.pdf)] [[url](https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwixt5-ks9jQAhWBiLwKHTcaC_oQFgguMAE&url=https%3A%2F%2Farxiv.org%2Fpdf%2F1606.04164&usg=AFQjCNE8wtAunVCjcDjilk5cyovuj_zlYA)]
