## nature language process

### deep learning

- Automatic Rule Extraction from Long Short Term Memory Networks. [[arXiv](https://arxiv.org/abs/1702.02540)]
- Deep Recurrent Neural Network for Protein Function Prediction from Sequence. [[arXiv](https://arxiv.org/abs/1701.08318)]
- Deep Voice: Real-time Neural Text-to-Speech. [[arXiv](https://arxiv.org/abs/1702.07825)] :star:
- Dialog Context Language Modeling with Recurrent Neural Networks. [[arXiv](https://arxiv.org/abs/1701.04056)]
- dna2vec: Consistent vector representations of variable-length k-mers. [[arXiv](https://arxiv.org/abs/1701.06279)] [[code](https://pnpnpn.github.io/dna2vec/)]
- Joint Semantic Synthesis and Morphological Analysis of the Derived Word. [[arXiv](https://arxiv.org/abs/1701.00946)]
- LanideNN: Multilingual Language Identification on Character Window. [[arXiv](https://arxiv.org/abs/1701.03338)] [[code](https://github.com/tomkocmi/LanideNN)]
- Learning a Natural Language Interface with Neural Programmer. [[arXiv](https://arxiv.org/abs/1611.08945)] [[tensorflow](https://github.com/tensorflow/models/tree/master/neural_programmer)] :star:
- Learning Arbitrary Potentials in CRFs with Gradient Descent. [[arXiv](https://arxiv.org/abs/1701.06805)]
- Multi-level Representations for Fine-Grained Typing of Knowledge Base Entities. [[arXiv](https://arxiv.org/abs/1701.02025)]
- Neural Probabilistic Model for Non-projective MST Parsing. [[arXiv](https://arxiv.org/abs/1701.00874)]
- One Representation per Word - Does it make Sense for Composition?.  [[arXiv](https://arxiv.org/abs/1702.06696)]
- Outlier Detection for Text Data : An Extended Version. [[arXiv](https://128.84.21.199/abs/1701.01325v1)]
- Person Search with Natural Language Description. [[arXiv](https://arxiv.org/abs/1702.05729)]
- Recurrent Recommender Networks. [[pdf](http://alexbeutel.com/papers/rrn_wsdm2017.pdf)]
- Symbolic, Distributed and Distributional Representations for Natural Language Processing in the Era of Deep Learning: a Survey. [[arXiv](https://arxiv.org/abs/1702.00764)]
- Transfer Learning for Low-Resource Chinese Word Segmentation with a Novel Neural Network. [[arXiv](https://arxiv.org/abs/1702.04488)] [[code](https://github.com/jincy520/Low-Resource-CWS-)]
- Vector Embedding of Wikipedia Concepts and Entities. [[arXiv](https://arxiv.org/abs/1702.03470)] [[code](https://github.com/ehsansherkat/ConVec)]
- VINet: Visual-Inertial Odometry as a Sequence-to-Sequence Learning Problem. [[arXiv](https://arxiv.org/abs/1701.08376)]

### Attention and memory 

- End-to-End Attention based Text-Dependent Speaker Verification. [[arXiv](https://arxiv.org/abs/1701.00562)]
- Frustratingly Short Attention Spans in Neural Language Modeling. [[arXiv](https://arxiv.org/abs/1702.04521)]
- Structural Attention Neural Networks for improved sentiment analysis. [[arXiv](https://arxiv.org/abs/1701.01811)]

### Generative learning

- [Adversarial Learning for Neural Dialogue Generation.](https://zhuanlan.zhihu.com/p/25027693) [[arXiv](https://arxiv.org/abs/1701.06547)]
